{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3965e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout, MaxPooling2D, BatchNormalization, Reshape\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasAdamOptimizer\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras_vectorized import VectorizedDPKerasAdamOptimizer\n",
    "from tensorflow_privacy.privacy.analysis.compute_noise_from_budget_lib import compute_noise\n",
    "\n",
    "\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack import membership_inference_attack as mia\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackInputData\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import SlicingSpec\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackType\n",
    "\n",
    "import tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.plotting as plotting\n",
    "\n",
    "import numpy as np\n",
    "import scipy as scp\n",
    "from scipy import special\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4357994b",
   "metadata": {},
   "outputs": [],
   "source": [
    "headers = ['age','workclass','fnlwgt','education','education-num','marital-status',\n",
    "           'occupation','relationship','race','sex','capital-gain','capital-loss',\n",
    "           'hours-per-week','native-country','class']\n",
    "adult = pd.read_csv('../../datasets/adult.data', \n",
    "                    sep=', ', names=headers, na_values='?', engine='python')\n",
    "\n",
    "# Drop all records with missing values\n",
    "adult.dropna(inplace=True)\n",
    "adult.reset_index(drop=True, inplace=True)\n",
    "# Drop fnlwgt, not interesting for ML\n",
    "adult.drop('fnlwgt', axis=1, inplace=True)\n",
    "adult.drop('education', axis=1, inplace=True)\n",
    "\n",
    "# Convert objects to categories\n",
    "obj_columns = adult.select_dtypes(['object']).columns\n",
    "adult[obj_columns] = adult[obj_columns].astype('category')\n",
    "\n",
    "num_columns = adult.select_dtypes(['int64']).columns\n",
    "adult[num_columns] = adult[num_columns].astype('float64')\n",
    "for c in num_columns:\n",
    "    adult[c] /= (adult[c].max()-adult[c].min())\n",
    "adult['class'] = adult['class'].cat.codes\n",
    "\n",
    "obj_columns = adult.select_dtypes(['category']).columns\n",
    "\n",
    "adult.replace(['Divorced', \n",
    "               'Married-AF-spouse', \n",
    "               'Married-civ-spouse', \n",
    "               'Married-spouse-absent',\n",
    "               'Never-married',\n",
    "               'Separated',\n",
    "               'Widowed'\n",
    "              ],\n",
    "              ['not married',\n",
    "               'married',\n",
    "               'married',\n",
    "               'married',\n",
    "               'not married',\n",
    "               'not married',\n",
    "               'not married'\n",
    "              ], inplace = True)\n",
    "\n",
    "adult = pd.get_dummies(adult, columns=obj_columns)\n",
    "X = np.array(adult.drop('class', axis=1))\n",
    "y = np.array(adult['class'])\n",
    "y = np.eye(2)[y]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9e4d5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 15e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7336b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def membership_inference_attack(model, X_train, X_test, y_train, y_test):\n",
    "    print('Predict on train...')\n",
    "    logits_train = model.predict(X_train, batch_size=batch_size)\n",
    "    print('Predict on test...')\n",
    "    logits_test = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    print('Apply softmax to get probabilities from logits...')\n",
    "    prob_train = special.softmax(logits_train, axis=1)\n",
    "    prob_test = special.softmax(logits_test, axis=1)\n",
    "\n",
    "    print('Compute losses...')\n",
    "    cce = tf.keras.backend.categorical_crossentropy\n",
    "    constant = tf.keras.backend.constant\n",
    "\n",
    "    loss_train = cce(constant(y_train), constant(prob_train), from_logits=False).numpy()\n",
    "    loss_test = cce(constant(y_test), constant(prob_test), from_logits=False).numpy()\n",
    "    \n",
    "    labels_train = np.argmax(y_train, axis=1)\n",
    "    labels_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    input = AttackInputData(\n",
    "      logits_train = logits_train,\n",
    "      logits_test = logits_test,\n",
    "      loss_train = loss_train,\n",
    "      loss_test = loss_test,\n",
    "      labels_train = labels_train,\n",
    "      labels_test = labels_test\n",
    "    )\n",
    "\n",
    "    # Run several attacks for different data slices\n",
    "    attacks_result = mia.run_attacks(input,\n",
    "                                     SlicingSpec(\n",
    "                                         entire_dataset = True,\n",
    "                                         by_class = True,\n",
    "                                         by_classification_correctness = True\n",
    "                                     ),\n",
    "                                     attack_types = [\n",
    "                                         AttackType.THRESHOLD_ATTACK,\n",
    "                                         AttackType.LOGISTIC_REGRESSION,\n",
    "                                         AttackType.MULTI_LAYERED_PERCEPTRON,\n",
    "                                         AttackType.RANDOM_FOREST, \n",
    "                                         AttackType.K_NEAREST_NEIGHBORS,\n",
    "                                         AttackType.THRESHOLD_ENTROPY_ATTACK\n",
    "                                     ])\n",
    "\n",
    "    # Plot the ROC curve of the best classifier\n",
    "#     fig = plotting.plot_roc_curve(\n",
    "#         attacks_result.get_result_with_max_auc().roc_curve)\n",
    "\n",
    "    # Print a user-friendly summary of the attacks\n",
    "    print(attacks_result.summary(by_slices = True))\n",
    "    time.sleep(5)\n",
    "    return attacks_result.get_result_with_max_auc().get_auc(), attacks_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa85c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_nn(dropout=None, regularizer=None):\n",
    "    input_data = Input(shape = X_train[0].shape)\n",
    "    x = Dense(40, activation='relu', kernel_regularizer=regularizer)(input_data)\n",
    "    if dropout is not None:\n",
    "        x = Dropout(dropout)(x)\n",
    "    x = Dense(40, activation='relu', kernel_regularizer=regularizer)(x)\n",
    "    if dropout is not None:\n",
    "        x = Dropout(dropout)(x)\n",
    "    output = Dense(2, kernel_regularizer=regularizer)(x)\n",
    "\n",
    "    model = Model(input_data, output)\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "            \n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_dp_nn(noise_multiplier, l2_norm_clip, microbatches):\n",
    "    input_data = Input(shape = X_train[0].shape)\n",
    "    x = Dense(40, activation='relu')(input_data)\n",
    "    x = Dense(40, activation='relu')(x)\n",
    "    output = Dense(2)(x)\n",
    "\n",
    "    model = Model(input_data, output)\n",
    "    \n",
    "    optimizer = DPKerasAdamOptimizer(\n",
    "                            l2_norm_clip=l2_norm_clip,\n",
    "                            noise_multiplier=noise_multiplier,\n",
    "                            num_microbatches=microbatches,\n",
    "                            learning_rate=learning_rate)\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b5777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "421/421 [==============================] - 3s 3ms/step - loss: 0.4018 - accuracy: 0.8115 - val_loss: 0.3726 - val_accuracy: 0.8219\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 1s 2ms/step - loss: 0.3506 - accuracy: 0.8353 - val_loss: 0.3471 - val_accuracy: 0.8344\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 1s 2ms/step - loss: 0.3352 - accuracy: 0.8437 - val_loss: 0.3386 - val_accuracy: 0.8419\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 1s 2ms/step - loss: 0.3290 - accuracy: 0.8471 - val_loss: 0.3357 - val_accuracy: 0.8438\n",
      "Epoch 5/50\n",
      "280/421 [==================>...........] - ETA: 0s - loss: 0.3208 - accuracy: 0.8514"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-7ba56dfb1447>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Train network until convergence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     r = model.fit(X_train, \n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 48\n",
    "attacks = 1\n",
    "settings = [\n",
    "    (None,None),\n",
    "    (0.25,None),\n",
    "    (0.50,None),\n",
    "    (0.75,None),\n",
    "    (None,'l2'),\n",
    "    (0.25,'l2'),\n",
    "    (0.50,'l2'),\n",
    "    (0.75,'l2'),\n",
    "]\n",
    "results_summary = []\n",
    "\n",
    "for drop, reg in settings:\n",
    "    # Instantiate network\n",
    "    model = create_nn(dropout=drop, regularizer=reg)\n",
    "    \n",
    "    # Train network until convergence\n",
    "    start_time = time.time()\n",
    "    r = model.fit(X_train, \n",
    "                y_train, \n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=epochs, \n",
    "                batch_size=batch_size\n",
    "               )\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "\n",
    "    # MIA \n",
    "    aauc = []\n",
    "    aadv = []\n",
    "    for _ in range(attacks):\n",
    "        auc, adv = membership_inference_attack(model, X_train, X_test, y_train, y_test)\n",
    "        time.sleep(5)\n",
    "        aauc.append(auc)\n",
    "        aadv.append(adv)\n",
    "    mauc = sum(aauc) / attacks\n",
    "    madv = sum(aadv) / attacks\n",
    "\n",
    "    # Write result summary\n",
    "    summ = ', '.join(map(str,[\n",
    "        len(r.history['loss']), #epochs\n",
    "        drop,\n",
    "        reg,\n",
    "        r.history['loss'][-1], \n",
    "        r.history['val_loss'][-1],\n",
    "        r.history['accuracy'][-1],\n",
    "        r.history['val_accuracy'][-1],\n",
    "        time_elapsed,\n",
    "        mauc,\n",
    "        madv\n",
    "    ]))\n",
    "\n",
    "    results_summary.append(summ)\n",
    "    print('='*40)\n",
    "    \n",
    "    \n",
    "print('Epochs, Dropout, Regularizer, Loss, Val loss, Accuracy, Val accuracy, Time, AUC, Advantage')\n",
    "for r in results_summary:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "80f750ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 17994.001391472444 iterated over 21050 steps satisfies differential privacy with eps = 0.01 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 16s 36ms/step - loss: 0.7564 - accuracy: 0.2844 - val_loss: 0.7583 - val_accuracy: 0.2768\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7601 - accuracy: 0.2799 - val_loss: 0.7614 - val_accuracy: 0.2755\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7569 - accuracy: 0.2869 - val_loss: 0.7544 - val_accuracy: 0.2822\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.7568 - accuracy: 0.2831 - val_loss: 0.7591 - val_accuracy: 0.2756\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7555 - accuracy: 0.2863 - val_loss: 0.7536 - val_accuracy: 0.2813\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.7546 - accuracy: 0.2881 - val_loss: 0.7533 - val_accuracy: 0.2815\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7519 - accuracy: 0.2904 - val_loss: 0.7530 - val_accuracy: 0.2824\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7532 - accuracy: 0.2877 - val_loss: 0.7536 - val_accuracy: 0.2820\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.7527 - accuracy: 0.2896 - val_loss: 0.7519 - val_accuracy: 0.2859\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.7521 - accuracy: 0.2931 - val_loss: 0.7524 - val_accuracy: 0.2856\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7568 - accuracy: 0.2855 - val_loss: 0.7576 - val_accuracy: 0.2773\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7565 - accuracy: 0.2843 - val_loss: 0.7580 - val_accuracy: 0.2765\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7583 - accuracy: 0.2790 - val_loss: 0.7594 - val_accuracy: 0.2730\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7592 - accuracy: 0.2778 - val_loss: 0.7616 - val_accuracy: 0.2703\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7619 - accuracy: 0.2740 - val_loss: 0.7626 - val_accuracy: 0.2699\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7651 - accuracy: 0.2721 - val_loss: 0.7684 - val_accuracy: 0.2660\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7638 - accuracy: 0.2738 - val_loss: 0.7611 - val_accuracy: 0.2726\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7632 - accuracy: 0.2746 - val_loss: 0.7659 - val_accuracy: 0.2685\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7663 - accuracy: 0.2715 - val_loss: 0.7672 - val_accuracy: 0.2664\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7642 - accuracy: 0.2723 - val_loss: 0.7686 - val_accuracy: 0.2644\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.7643 - accuracy: 0.2710 - val_loss: 0.7671 - val_accuracy: 0.2651\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.7674 - accuracy: 0.2696 - val_loss: 0.7699 - val_accuracy: 0.2636\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.7692 - accuracy: 0.2689 - val_loss: 0.7688 - val_accuracy: 0.2642\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7652 - accuracy: 0.2715 - val_loss: 0.7671 - val_accuracy: 0.2658\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.7661 - accuracy: 0.2727 - val_loss: 0.7679 - val_accuracy: 0.2657\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7691 - accuracy: 0.2723 - val_loss: 0.7735 - val_accuracy: 0.2626\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7773 - accuracy: 0.2659 - val_loss: 0.7818 - val_accuracy: 0.2577\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.7831 - accuracy: 0.2628 - val_loss: 0.7831 - val_accuracy: 0.2571\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7865 - accuracy: 0.2614 - val_loss: 0.7915 - val_accuracy: 0.2538\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7888 - accuracy: 0.2608 - val_loss: 0.7899 - val_accuracy: 0.2551\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7891 - accuracy: 0.2615 - val_loss: 0.7884 - val_accuracy: 0.2549\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7889 - accuracy: 0.2619 - val_loss: 0.7910 - val_accuracy: 0.2549\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7900 - accuracy: 0.2619 - val_loss: 0.7910 - val_accuracy: 0.2554\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7925 - accuracy: 0.2607 - val_loss: 0.7946 - val_accuracy: 0.2540\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7927 - accuracy: 0.2606 - val_loss: 0.7903 - val_accuracy: 0.2555\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7870 - accuracy: 0.2635 - val_loss: 0.7823 - val_accuracy: 0.2608\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7818 - accuracy: 0.2689 - val_loss: 0.7841 - val_accuracy: 0.2607\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7864 - accuracy: 0.2643 - val_loss: 0.7895 - val_accuracy: 0.2562\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7895 - accuracy: 0.2628 - val_loss: 0.7919 - val_accuracy: 0.2572\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7879 - accuracy: 0.2639 - val_loss: 0.7854 - val_accuracy: 0.2617\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7810 - accuracy: 0.2694 - val_loss: 0.7779 - val_accuracy: 0.2652\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.7785 - accuracy: 0.2711 - val_loss: 0.7821 - val_accuracy: 0.2609\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7804 - accuracy: 0.2688 - val_loss: 0.7797 - val_accuracy: 0.2618\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7789 - accuracy: 0.2691 - val_loss: 0.7799 - val_accuracy: 0.2622\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7789 - accuracy: 0.2687 - val_loss: 0.7799 - val_accuracy: 0.2614\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7808 - accuracy: 0.2678 - val_loss: 0.7808 - val_accuracy: 0.2607\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7793 - accuracy: 0.2682 - val_loss: 0.7818 - val_accuracy: 0.2593\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.7794 - accuracy: 0.2674 - val_loss: 0.7788 - val_accuracy: 0.2609\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.7795 - accuracy: 0.2676 - val_loss: 0.7841 - val_accuracy: 0.2597\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.7798 - accuracy: 0.2673 - val_loss: 0.7803 - val_accuracy: 0.2603\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an AUC of 0.53 on slice CLASS=0\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an advantage of 0.07 on slice CLASS=1\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  K_NEAREST_NEIGHBORS (with 9954 training and 9954 test examples) achieved an AUC of 0.50\n",
      "  MULTI_LAYERED_PERCEPTRON (with 9954 training and 9954 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an AUC of 0.53\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an advantage of 0.05\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  THRESHOLD_ATTACK (with 5055 training and 2453 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an advantage of 0.07\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  THRESHOLD_ATTACK (with 5412 training and 2591 test examples) achieved an AUC of 0.49\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2591 training and 2591 test examples) achieved an advantage of 0.05\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  K_NEAREST_NEIGHBORS (with 7363 training and 7363 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 7363 training and 7363 test examples) achieved an advantage of 0.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 14.309830337352679 iterated over 21050 steps satisfies differential privacy with eps = 0.1 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.6994 - accuracy: 0.4622 - val_loss: 0.6759 - val_accuracy: 0.6319\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.6547 - accuracy: 0.7096 - val_loss: 0.6353 - val_accuracy: 0.7449\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.6208 - accuracy: 0.7462 - val_loss: 0.6080 - val_accuracy: 0.7532\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5983 - accuracy: 0.7494 - val_loss: 0.5862 - val_accuracy: 0.7537\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5808 - accuracy: 0.7498 - val_loss: 0.5741 - val_accuracy: 0.7536\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5695 - accuracy: 0.7499 - val_loss: 0.5635 - val_accuracy: 0.7536\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5608 - accuracy: 0.7499 - val_loss: 0.5560 - val_accuracy: 0.7536\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5543 - accuracy: 0.7499 - val_loss: 0.5503 - val_accuracy: 0.7536\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5498 - accuracy: 0.7499 - val_loss: 0.5463 - val_accuracy: 0.7536\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.5458 - accuracy: 0.7499 - val_loss: 0.5416 - val_accuracy: 0.7536\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5419 - accuracy: 0.7499 - val_loss: 0.5387 - val_accuracy: 0.7536\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5387 - accuracy: 0.7499 - val_loss: 0.5367 - val_accuracy: 0.7536\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5375 - accuracy: 0.7499 - val_loss: 0.5350 - val_accuracy: 0.7536\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 16s 39ms/step - loss: 0.5362 - accuracy: 0.7499 - val_loss: 0.5336 - val_accuracy: 0.7536\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.5340 - accuracy: 0.7499 - val_loss: 0.5312 - val_accuracy: 0.7536\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5318 - accuracy: 0.7499 - val_loss: 0.5281 - val_accuracy: 0.7536\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5286 - accuracy: 0.7499 - val_loss: 0.5257 - val_accuracy: 0.7536\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5282 - accuracy: 0.7499 - val_loss: 0.5264 - val_accuracy: 0.7536\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5277 - accuracy: 0.7499 - val_loss: 0.5257 - val_accuracy: 0.7536\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5264 - accuracy: 0.7499 - val_loss: 0.5236 - val_accuracy: 0.7536\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5245 - accuracy: 0.7499 - val_loss: 0.5213 - val_accuracy: 0.7536\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5239 - accuracy: 0.7499 - val_loss: 0.5227 - val_accuracy: 0.7536\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5239 - accuracy: 0.7499 - val_loss: 0.5199 - val_accuracy: 0.7536\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5200 - accuracy: 0.7499 - val_loss: 0.5176 - val_accuracy: 0.7536\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.5190 - accuracy: 0.7499 - val_loss: 0.5173 - val_accuracy: 0.7536\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5187 - accuracy: 0.7499 - val_loss: 0.5164 - val_accuracy: 0.7536\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5166 - accuracy: 0.7499 - val_loss: 0.5151 - val_accuracy: 0.7536\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5151 - accuracy: 0.7499 - val_loss: 0.5128 - val_accuracy: 0.7536\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5133 - accuracy: 0.7499 - val_loss: 0.5115 - val_accuracy: 0.7536\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5128 - accuracy: 0.7499 - val_loss: 0.5122 - val_accuracy: 0.7536\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5119 - accuracy: 0.7499 - val_loss: 0.5107 - val_accuracy: 0.7536\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5111 - accuracy: 0.7499 - val_loss: 0.5087 - val_accuracy: 0.7536\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5093 - accuracy: 0.7499 - val_loss: 0.5080 - val_accuracy: 0.7536\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5073 - accuracy: 0.7499 - val_loss: 0.5054 - val_accuracy: 0.7536\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5044 - accuracy: 0.7499 - val_loss: 0.5032 - val_accuracy: 0.7536\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5034 - accuracy: 0.7499 - val_loss: 0.5032 - val_accuracy: 0.7536\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5028 - accuracy: 0.7499 - val_loss: 0.5031 - val_accuracy: 0.7536\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5025 - accuracy: 0.7499 - val_loss: 0.5012 - val_accuracy: 0.7536\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4996 - accuracy: 0.7499 - val_loss: 0.4992 - val_accuracy: 0.7536\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4987 - accuracy: 0.7499 - val_loss: 0.4972 - val_accuracy: 0.7536\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4960 - accuracy: 0.7499 - val_loss: 0.4955 - val_accuracy: 0.7536\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4950 - accuracy: 0.7499 - val_loss: 0.4950 - val_accuracy: 0.7536\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4944 - accuracy: 0.7499 - val_loss: 0.4943 - val_accuracy: 0.7536\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4937 - accuracy: 0.7499 - val_loss: 0.4949 - val_accuracy: 0.7536\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4938 - accuracy: 0.7499 - val_loss: 0.4936 - val_accuracy: 0.7536\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4910 - accuracy: 0.7499 - val_loss: 0.4903 - val_accuracy: 0.7536\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4896 - accuracy: 0.7499 - val_loss: 0.4917 - val_accuracy: 0.7536\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4908 - accuracy: 0.7499 - val_loss: 0.4908 - val_accuracy: 0.7536\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4888 - accuracy: 0.7499 - val_loss: 0.4891 - val_accuracy: 0.7536\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 21s 49ms/step - loss: 0.4864 - accuracy: 0.7499 - val_loss: 0.4876 - val_accuracy: 0.7536\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an AUC of 0.54 on slice CLASS=1\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an advantage of 0.08 on slice CLASS=1\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  RANDOM_FOREST (with 9954 training and 9954 test examples) achieved an AUC of 0.52\n",
      "  RANDOM_FOREST (with 9954 training and 9954 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  K_NEAREST_NEIGHBORS (with 7501 training and 7501 test examples) achieved an AUC of 0.51\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an AUC of 0.54\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an advantage of 0.08\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  K_NEAREST_NEIGHBORS (with 7501 training and 7501 test examples) achieved an AUC of 0.52\n",
      "  MULTI_LAYERED_PERCEPTRON (with 7501 training and 7501 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an AUC of 0.53\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an advantage of 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 3.0864306316599435 iterated over 21050 steps satisfies differential privacy with eps = 0.5 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 21s 49ms/step - loss: 0.6241 - accuracy: 0.6776 - val_loss: 0.5667 - val_accuracy: 0.7483\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 22s 53ms/step - loss: 0.5540 - accuracy: 0.7487 - val_loss: 0.5462 - val_accuracy: 0.7531\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 21s 51ms/step - loss: 0.5483 - accuracy: 0.7498 - val_loss: 0.5454 - val_accuracy: 0.7536\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 21s 49ms/step - loss: 0.5472 - accuracy: 0.7500 - val_loss: 0.5442 - val_accuracy: 0.7535\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 20s 48ms/step - loss: 0.5464 - accuracy: 0.7500 - val_loss: 0.5416 - val_accuracy: 0.7535\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 18s 42ms/step - loss: 0.5404 - accuracy: 0.7500 - val_loss: 0.5384 - val_accuracy: 0.7535\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5365 - accuracy: 0.7501 - val_loss: 0.5314 - val_accuracy: 0.7537\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5314 - accuracy: 0.7503 - val_loss: 0.5284 - val_accuracy: 0.7537\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5255 - accuracy: 0.7505 - val_loss: 0.5218 - val_accuracy: 0.7536\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5188 - accuracy: 0.7506 - val_loss: 0.5160 - val_accuracy: 0.7535\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.5147 - accuracy: 0.7507 - val_loss: 0.5121 - val_accuracy: 0.7535\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.5098 - accuracy: 0.7510 - val_loss: 0.5095 - val_accuracy: 0.7537\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5079 - accuracy: 0.7508 - val_loss: 0.5075 - val_accuracy: 0.7536\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5031 - accuracy: 0.7511 - val_loss: 0.5046 - val_accuracy: 0.7540\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5026 - accuracy: 0.7509 - val_loss: 0.5040 - val_accuracy: 0.7539\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4996 - accuracy: 0.7512 - val_loss: 0.4992 - val_accuracy: 0.7539\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4938 - accuracy: 0.7515 - val_loss: 0.4949 - val_accuracy: 0.7540\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4897 - accuracy: 0.7514 - val_loss: 0.4921 - val_accuracy: 0.7540\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4879 - accuracy: 0.7525 - val_loss: 0.4924 - val_accuracy: 0.7552\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4877 - accuracy: 0.7530 - val_loss: 0.4909 - val_accuracy: 0.7565\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4848 - accuracy: 0.7548 - val_loss: 0.4882 - val_accuracy: 0.7574\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4840 - accuracy: 0.7555 - val_loss: 0.4842 - val_accuracy: 0.7585\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4793 - accuracy: 0.7565 - val_loss: 0.4840 - val_accuracy: 0.7596\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4772 - accuracy: 0.7589 - val_loss: 0.4804 - val_accuracy: 0.7618\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4754 - accuracy: 0.7599 - val_loss: 0.4812 - val_accuracy: 0.7618\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4721 - accuracy: 0.7622 - val_loss: 0.4764 - val_accuracy: 0.7648\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4679 - accuracy: 0.7706 - val_loss: 0.4730 - val_accuracy: 0.7746\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4652 - accuracy: 0.7788 - val_loss: 0.4727 - val_accuracy: 0.7779\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4627 - accuracy: 0.7815 - val_loss: 0.4706 - val_accuracy: 0.7790\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4658 - accuracy: 0.7819 - val_loss: 0.4719 - val_accuracy: 0.7800\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4629 - accuracy: 0.7860 - val_loss: 0.4688 - val_accuracy: 0.7849\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4611 - accuracy: 0.7917 - val_loss: 0.4680 - val_accuracy: 0.7921\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4587 - accuracy: 0.8003 - val_loss: 0.4664 - val_accuracy: 0.7999\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4588 - accuracy: 0.8014 - val_loss: 0.4654 - val_accuracy: 0.7981\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4562 - accuracy: 0.8035 - val_loss: 0.4630 - val_accuracy: 0.7985\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4521 - accuracy: 0.8035 - val_loss: 0.4621 - val_accuracy: 0.7991\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4532 - accuracy: 0.8045 - val_loss: 0.4607 - val_accuracy: 0.7992\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4517 - accuracy: 0.8052 - val_loss: 0.4623 - val_accuracy: 0.7997\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4512 - accuracy: 0.8058 - val_loss: 0.4595 - val_accuracy: 0.7999\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4489 - accuracy: 0.8060 - val_loss: 0.4579 - val_accuracy: 0.8005\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4479 - accuracy: 0.8060 - val_loss: 0.4569 - val_accuracy: 0.8008\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4477 - accuracy: 0.8063 - val_loss: 0.4596 - val_accuracy: 0.8009\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4489 - accuracy: 0.8065 - val_loss: 0.4568 - val_accuracy: 0.8008\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4464 - accuracy: 0.8067 - val_loss: 0.4574 - val_accuracy: 0.8010\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4451 - accuracy: 0.8067 - val_loss: 0.4551 - val_accuracy: 0.8012\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4453 - accuracy: 0.8067 - val_loss: 0.4546 - val_accuracy: 0.8014\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4448 - accuracy: 0.8067 - val_loss: 0.4541 - val_accuracy: 0.8013\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4434 - accuracy: 0.8068 - val_loss: 0.4531 - val_accuracy: 0.8018\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4426 - accuracy: 0.8075 - val_loss: 0.4544 - val_accuracy: 0.8017\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4430 - accuracy: 0.8077 - val_loss: 0.4544 - val_accuracy: 0.8017\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  K_NEAREST_NEIGHBORS (with 1974 training and 1974 test examples) achieved an AUC of 0.54 on slice CORRECTLY_CLASSIFIED=False\n",
      "  MULTI_LAYERED_PERCEPTRON (with 1974 training and 1974 test examples) achieved an advantage of 0.08 on slice CORRECTLY_CLASSIFIED=False\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  K_NEAREST_NEIGHBORS (with 9954 training and 9954 test examples) achieved an AUC of 0.51\n",
      "  LOGISTIC_REGRESSION (with 9954 training and 9954 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  K_NEAREST_NEIGHBORS (with 7501 training and 7501 test examples) achieved an AUC of 0.51\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  THRESHOLD_ATTACK (with 5055 training and 2453 test examples) achieved an AUC of 0.51\n",
      "  RANDOM_FOREST (with 2453 training and 2453 test examples) achieved an advantage of 0.05\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  RANDOM_FOREST (with 7980 training and 7980 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 7980 training and 7980 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  K_NEAREST_NEIGHBORS (with 1974 training and 1974 test examples) achieved an AUC of 0.54\n",
      "  MULTI_LAYERED_PERCEPTRON (with 1974 training and 1974 test examples) achieved an advantage of 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 1.7217127690788603 iterated over 21050 steps satisfies differential privacy with eps = 1 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 16s 36ms/step - loss: 0.5427 - accuracy: 0.7499 - val_loss: 0.5281 - val_accuracy: 0.7536\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.5278 - accuracy: 0.7499 - val_loss: 0.5217 - val_accuracy: 0.7536\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.5187 - accuracy: 0.7499 - val_loss: 0.5097 - val_accuracy: 0.7536\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.4976 - val_accuracy: 0.7536\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4929 - accuracy: 0.7499 - val_loss: 0.4879 - val_accuracy: 0.7536\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4837 - accuracy: 0.7499 - val_loss: 0.4823 - val_accuracy: 0.7536\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4795 - accuracy: 0.7499 - val_loss: 0.4778 - val_accuracy: 0.7536\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4739 - accuracy: 0.7499 - val_loss: 0.4735 - val_accuracy: 0.7536\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4711 - accuracy: 0.7498 - val_loss: 0.4722 - val_accuracy: 0.7537\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4661 - accuracy: 0.7506 - val_loss: 0.4719 - val_accuracy: 0.7544\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4677 - accuracy: 0.7523 - val_loss: 0.4705 - val_accuracy: 0.7589\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4652 - accuracy: 0.7567 - val_loss: 0.4701 - val_accuracy: 0.7603\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4650 - accuracy: 0.7588 - val_loss: 0.4663 - val_accuracy: 0.7643\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4616 - accuracy: 0.7644 - val_loss: 0.4670 - val_accuracy: 0.7737\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4597 - accuracy: 0.7767 - val_loss: 0.4655 - val_accuracy: 0.7786\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4571 - accuracy: 0.7797 - val_loss: 0.4618 - val_accuracy: 0.7808\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4561 - accuracy: 0.7820 - val_loss: 0.4610 - val_accuracy: 0.7806\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4527 - accuracy: 0.7828 - val_loss: 0.4614 - val_accuracy: 0.7807\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4504 - accuracy: 0.7845 - val_loss: 0.4597 - val_accuracy: 0.7827\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4503 - accuracy: 0.7869 - val_loss: 0.4588 - val_accuracy: 0.7854\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4480 - accuracy: 0.7898 - val_loss: 0.4558 - val_accuracy: 0.7883\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4452 - accuracy: 0.7918 - val_loss: 0.4544 - val_accuracy: 0.7907\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4445 - accuracy: 0.7945 - val_loss: 0.4523 - val_accuracy: 0.7956\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4413 - accuracy: 0.8017 - val_loss: 0.4523 - val_accuracy: 0.8011\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4406 - accuracy: 0.8063 - val_loss: 0.4524 - val_accuracy: 0.8030\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4400 - accuracy: 0.8074 - val_loss: 0.4516 - val_accuracy: 0.8028\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4398 - accuracy: 0.8078 - val_loss: 0.4474 - val_accuracy: 0.8030\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4379 - accuracy: 0.8087 - val_loss: 0.4506 - val_accuracy: 0.8026\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4369 - accuracy: 0.8087 - val_loss: 0.4489 - val_accuracy: 0.8034\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4369 - accuracy: 0.8103 - val_loss: 0.4491 - val_accuracy: 0.8029\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4363 - accuracy: 0.8116 - val_loss: 0.4504 - val_accuracy: 0.8039\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4368 - accuracy: 0.8128 - val_loss: 0.4508 - val_accuracy: 0.8051\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4392 - accuracy: 0.8132 - val_loss: 0.4533 - val_accuracy: 0.8055\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4375 - accuracy: 0.8134 - val_loss: 0.4523 - val_accuracy: 0.8058\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4402 - accuracy: 0.8132 - val_loss: 0.4528 - val_accuracy: 0.8057\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4391 - accuracy: 0.8137 - val_loss: 0.4531 - val_accuracy: 0.8060\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4402 - accuracy: 0.8141 - val_loss: 0.4545 - val_accuracy: 0.8060\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4396 - accuracy: 0.8140 - val_loss: 0.4534 - val_accuracy: 0.8064\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4396 - accuracy: 0.8141 - val_loss: 0.4548 - val_accuracy: 0.8060\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4408 - accuracy: 0.8144 - val_loss: 0.4553 - val_accuracy: 0.8068\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4418 - accuracy: 0.8152 - val_loss: 0.4581 - val_accuracy: 0.8072\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4445 - accuracy: 0.8152 - val_loss: 0.4613 - val_accuracy: 0.8073\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4458 - accuracy: 0.8158 - val_loss: 0.4587 - val_accuracy: 0.8077\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4442 - accuracy: 0.8169 - val_loss: 0.4612 - val_accuracy: 0.8080\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4458 - accuracy: 0.8173 - val_loss: 0.4622 - val_accuracy: 0.8084\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4458 - accuracy: 0.8176 - val_loss: 0.4620 - val_accuracy: 0.8084\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4465 - accuracy: 0.8179 - val_loss: 0.4639 - val_accuracy: 0.8088\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4482 - accuracy: 0.8183 - val_loss: 0.4643 - val_accuracy: 0.8088\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4495 - accuracy: 0.8180 - val_loss: 0.4665 - val_accuracy: 0.8088\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4502 - accuracy: 0.8187 - val_loss: 0.4673 - val_accuracy: 0.8090\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an AUC of 0.52 on slice CLASS=1\n",
      "  RANDOM_FOREST (with 2453 training and 2453 test examples) achieved an advantage of 0.08 on slice CLASS=1\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  K_NEAREST_NEIGHBORS (with 9954 training and 9954 test examples) achieved an AUC of 0.52\n",
      "  MULTI_LAYERED_PERCEPTRON (with 9954 training and 9954 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  THRESHOLD_ATTACK (with 15153 training and 7501 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 7501 training and 7501 test examples) achieved an advantage of 0.05\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an AUC of 0.52\n",
      "  RANDOM_FOREST (with 2453 training and 2453 test examples) achieved an advantage of 0.08\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  K_NEAREST_NEIGHBORS (with 8053 training and 8053 test examples) achieved an AUC of 0.51\n",
      "  K_NEAREST_NEIGHBORS (with 8053 training and 8053 test examples) achieved an advantage of 0.02\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  LOGISTIC_REGRESSION (with 1901 training and 1901 test examples) achieved an AUC of 0.51\n",
      "  LOGISTIC_REGRESSION (with 1901 training and 1901 test examples) achieved an advantage of 0.04\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 1.0674083630051678 iterated over 21050 steps satisfies differential privacy with eps = 2 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.5917 - accuracy: 0.6977 - val_loss: 0.5255 - val_accuracy: 0.7536\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5242 - accuracy: 0.7499 - val_loss: 0.5139 - val_accuracy: 0.7536\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5120 - accuracy: 0.7499 - val_loss: 0.4990 - val_accuracy: 0.7536\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4966 - accuracy: 0.7499 - val_loss: 0.4869 - val_accuracy: 0.7536\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4843 - accuracy: 0.7498 - val_loss: 0.4791 - val_accuracy: 0.7536\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4775 - accuracy: 0.7500 - val_loss: 0.4730 - val_accuracy: 0.7541\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4713 - accuracy: 0.7509 - val_loss: 0.4713 - val_accuracy: 0.7564\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4686 - accuracy: 0.7519 - val_loss: 0.4630 - val_accuracy: 0.7568\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4631 - accuracy: 0.7543 - val_loss: 0.4634 - val_accuracy: 0.7603\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4607 - accuracy: 0.7604 - val_loss: 0.4584 - val_accuracy: 0.7686\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4554 - accuracy: 0.7729 - val_loss: 0.4548 - val_accuracy: 0.7820\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4515 - accuracy: 0.7828 - val_loss: 0.4526 - val_accuracy: 0.7857\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4492 - accuracy: 0.7848 - val_loss: 0.4481 - val_accuracy: 0.7871\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4450 - accuracy: 0.7871 - val_loss: 0.4456 - val_accuracy: 0.7890\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4429 - accuracy: 0.7930 - val_loss: 0.4432 - val_accuracy: 0.7958\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4385 - accuracy: 0.8036 - val_loss: 0.4391 - val_accuracy: 0.8042\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4380 - accuracy: 0.8071 - val_loss: 0.4390 - val_accuracy: 0.8067\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4361 - accuracy: 0.8108 - val_loss: 0.4367 - val_accuracy: 0.8058\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4345 - accuracy: 0.8128 - val_loss: 0.4381 - val_accuracy: 0.8065\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4337 - accuracy: 0.8134 - val_loss: 0.4357 - val_accuracy: 0.8075\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4316 - accuracy: 0.8158 - val_loss: 0.4397 - val_accuracy: 0.8086\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4334 - accuracy: 0.8158 - val_loss: 0.4399 - val_accuracy: 0.8099\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4339 - accuracy: 0.8161 - val_loss: 0.4390 - val_accuracy: 0.8106\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4351 - accuracy: 0.8172 - val_loss: 0.4401 - val_accuracy: 0.8116\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4371 - accuracy: 0.8175 - val_loss: 0.4424 - val_accuracy: 0.8133\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4383 - accuracy: 0.8180 - val_loss: 0.4482 - val_accuracy: 0.8128\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4425 - accuracy: 0.8177 - val_loss: 0.4480 - val_accuracy: 0.8132\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4452 - accuracy: 0.8185 - val_loss: 0.4522 - val_accuracy: 0.8137\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4471 - accuracy: 0.8188 - val_loss: 0.4562 - val_accuracy: 0.8143\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4489 - accuracy: 0.8196 - val_loss: 0.4567 - val_accuracy: 0.8153\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4515 - accuracy: 0.8193 - val_loss: 0.4605 - val_accuracy: 0.8159\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4545 - accuracy: 0.8208 - val_loss: 0.4591 - val_accuracy: 0.8166\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4547 - accuracy: 0.8204 - val_loss: 0.4634 - val_accuracy: 0.8170\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4577 - accuracy: 0.8204 - val_loss: 0.4674 - val_accuracy: 0.8167\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4603 - accuracy: 0.8207 - val_loss: 0.4703 - val_accuracy: 0.8165\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4620 - accuracy: 0.8205 - val_loss: 0.4704 - val_accuracy: 0.8176\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 16s 39ms/step - loss: 0.4630 - accuracy: 0.8206 - val_loss: 0.4724 - val_accuracy: 0.8181\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 16s 39ms/step - loss: 0.4650 - accuracy: 0.8204 - val_loss: 0.4718 - val_accuracy: 0.8188\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4639 - accuracy: 0.8208 - val_loss: 0.4783 - val_accuracy: 0.8188\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4676 - accuracy: 0.8210 - val_loss: 0.4736 - val_accuracy: 0.8187\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4660 - accuracy: 0.8207 - val_loss: 0.4749 - val_accuracy: 0.8190\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4673 - accuracy: 0.8207 - val_loss: 0.4727 - val_accuracy: 0.8194\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4669 - accuracy: 0.8212 - val_loss: 0.4753 - val_accuracy: 0.8194\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4659 - accuracy: 0.8212 - val_loss: 0.4813 - val_accuracy: 0.8195\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4696 - accuracy: 0.8215 - val_loss: 0.4782 - val_accuracy: 0.8195\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4686 - accuracy: 0.8220 - val_loss: 0.4784 - val_accuracy: 0.8194\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4692 - accuracy: 0.8216 - val_loss: 0.4799 - val_accuracy: 0.8195\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4712 - accuracy: 0.8225 - val_loss: 0.4798 - val_accuracy: 0.8194\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4715 - accuracy: 0.8223 - val_loss: 0.4816 - val_accuracy: 0.8194\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4724 - accuracy: 0.8225 - val_loss: 0.4829 - val_accuracy: 0.8191\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an AUC of 0.53 on slice CLASS=1\n",
      "  MULTI_LAYERED_PERCEPTRON (with 1801 training and 1801 test examples) achieved an advantage of 0.08 on slice CORRECTLY_CLASSIFIED=False\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  K_NEAREST_NEIGHBORS (with 9954 training and 9954 test examples) achieved an AUC of 0.51\n",
      "  K_NEAREST_NEIGHBORS (with 9954 training and 9954 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  THRESHOLD_ENTROPY_ATTACK (with 15153 training and 7501 test examples) achieved an AUC of 0.50\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an AUC of 0.53\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an advantage of 0.07\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  THRESHOLD_ENTROPY_ATTACK (with 16628 training and 8153 test examples) achieved an AUC of 0.50\n",
      "  RANDOM_FOREST (with 8153 training and 8153 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  RANDOM_FOREST (with 1801 training and 1801 test examples) achieved an AUC of 0.53\n",
      "  MULTI_LAYERED_PERCEPTRON (with 1801 training and 1801 test examples) achieved an advantage of 0.08\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 0.7767693318298682 iterated over 21050 steps satisfies differential privacy with eps = 4 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 16s 36ms/step - loss: 0.6244 - accuracy: 0.6680 - val_loss: 0.5488 - val_accuracy: 0.7535\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.5305 - accuracy: 0.7498 - val_loss: 0.5145 - val_accuracy: 0.7536\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.5059 - accuracy: 0.7499 - val_loss: 0.4966 - val_accuracy: 0.7535\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4912 - accuracy: 0.7498 - val_loss: 0.4808 - val_accuracy: 0.7533\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4784 - accuracy: 0.7525 - val_loss: 0.4768 - val_accuracy: 0.7572\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4748 - accuracy: 0.7561 - val_loss: 0.4707 - val_accuracy: 0.7595\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4669 - accuracy: 0.7581 - val_loss: 0.4718 - val_accuracy: 0.7608\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4624 - accuracy: 0.7639 - val_loss: 0.4674 - val_accuracy: 0.7676\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4585 - accuracy: 0.7697 - val_loss: 0.4631 - val_accuracy: 0.7709\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4535 - accuracy: 0.7776 - val_loss: 0.4582 - val_accuracy: 0.7806\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4487 - accuracy: 0.7962 - val_loss: 0.4569 - val_accuracy: 0.7988\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4460 - accuracy: 0.8063 - val_loss: 0.4533 - val_accuracy: 0.8025\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4439 - accuracy: 0.8079 - val_loss: 0.4532 - val_accuracy: 0.8042\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4427 - accuracy: 0.8102 - val_loss: 0.4561 - val_accuracy: 0.8062\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4452 - accuracy: 0.8111 - val_loss: 0.4497 - val_accuracy: 0.8060\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4434 - accuracy: 0.8125 - val_loss: 0.4549 - val_accuracy: 0.8073\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4455 - accuracy: 0.8125 - val_loss: 0.4598 - val_accuracy: 0.8076\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4487 - accuracy: 0.8134 - val_loss: 0.4627 - val_accuracy: 0.8086\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4522 - accuracy: 0.8136 - val_loss: 0.4694 - val_accuracy: 0.8084\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4573 - accuracy: 0.8138 - val_loss: 0.4747 - val_accuracy: 0.8083\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4635 - accuracy: 0.8134 - val_loss: 0.4811 - val_accuracy: 0.8079\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4656 - accuracy: 0.8137 - val_loss: 0.4857 - val_accuracy: 0.8082\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4699 - accuracy: 0.8135 - val_loss: 0.4843 - val_accuracy: 0.8081\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4722 - accuracy: 0.8135 - val_loss: 0.4896 - val_accuracy: 0.8081\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4756 - accuracy: 0.8134 - val_loss: 0.4934 - val_accuracy: 0.8078\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4781 - accuracy: 0.8137 - val_loss: 0.4957 - val_accuracy: 0.8083\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4793 - accuracy: 0.8137 - val_loss: 0.4953 - val_accuracy: 0.8081\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4794 - accuracy: 0.8141 - val_loss: 0.4980 - val_accuracy: 0.8080\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4805 - accuracy: 0.8143 - val_loss: 0.4961 - val_accuracy: 0.8086\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4812 - accuracy: 0.8143 - val_loss: 0.4961 - val_accuracy: 0.8088\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4819 - accuracy: 0.8143 - val_loss: 0.4959 - val_accuracy: 0.8091\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4822 - accuracy: 0.8145 - val_loss: 0.5027 - val_accuracy: 0.8089\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4845 - accuracy: 0.8151 - val_loss: 0.5006 - val_accuracy: 0.8093\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4849 - accuracy: 0.8150 - val_loss: 0.4977 - val_accuracy: 0.8094\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4836 - accuracy: 0.8154 - val_loss: 0.4990 - val_accuracy: 0.8097\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4834 - accuracy: 0.8154 - val_loss: 0.5014 - val_accuracy: 0.8094\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4825 - accuracy: 0.8157 - val_loss: 0.4983 - val_accuracy: 0.8095\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4816 - accuracy: 0.8156 - val_loss: 0.4972 - val_accuracy: 0.8099\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4818 - accuracy: 0.8160 - val_loss: 0.5008 - val_accuracy: 0.8101\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4828 - accuracy: 0.8162 - val_loss: 0.4932 - val_accuracy: 0.8101\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4790 - accuracy: 0.8165 - val_loss: 0.4993 - val_accuracy: 0.8103\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4814 - accuracy: 0.8162 - val_loss: 0.4970 - val_accuracy: 0.8108\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4798 - accuracy: 0.8170 - val_loss: 0.4994 - val_accuracy: 0.8111\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4805 - accuracy: 0.8171 - val_loss: 0.4985 - val_accuracy: 0.8117\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4790 - accuracy: 0.8181 - val_loss: 0.5002 - val_accuracy: 0.8120\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4789 - accuracy: 0.8178 - val_loss: 0.4991 - val_accuracy: 0.8123\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4781 - accuracy: 0.8183 - val_loss: 0.4970 - val_accuracy: 0.8125\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4767 - accuracy: 0.8188 - val_loss: 0.4963 - val_accuracy: 0.8122\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4767 - accuracy: 0.8188 - val_loss: 0.4875 - val_accuracy: 0.8137\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4729 - accuracy: 0.8201 - val_loss: 0.4920 - val_accuracy: 0.8132\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an AUC of 0.53 on slice CLASS=1\n",
      "  LOGISTIC_REGRESSION (with 1859 training and 1859 test examples) achieved an advantage of 0.06 on slice CORRECTLY_CLASSIFIED=False\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  K_NEAREST_NEIGHBORS (with 9954 training and 9954 test examples) achieved an AUC of 0.51\n",
      "  RANDOM_FOREST (with 9954 training and 9954 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  LOGISTIC_REGRESSION (with 7501 training and 7501 test examples) achieved an AUC of 0.51\n",
      "  MULTI_LAYERED_PERCEPTRON (with 7501 training and 7501 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an AUC of 0.53\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an advantage of 0.06\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  LOGISTIC_REGRESSION (with 8095 training and 8095 test examples) achieved an AUC of 0.50\n",
      "  MULTI_LAYERED_PERCEPTRON (with 8095 training and 8095 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  RANDOM_FOREST (with 1859 training and 1859 test examples) achieved an AUC of 0.51\n",
      "  LOGISTIC_REGRESSION (with 1859 training and 1859 test examples) achieved an advantage of 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 0.6223068197048801 iterated over 21050 steps satisfies differential privacy with eps = 8 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 18s 41ms/step - loss: 0.5760 - accuracy: 0.7425 - val_loss: 0.5330 - val_accuracy: 0.7536\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.5190 - accuracy: 0.7499 - val_loss: 0.4972 - val_accuracy: 0.7536\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4860 - accuracy: 0.7499 - val_loss: 0.4804 - val_accuracy: 0.7536\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4722 - accuracy: 0.7499 - val_loss: 0.4665 - val_accuracy: 0.7536\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4644 - accuracy: 0.7499 - val_loss: 0.4667 - val_accuracy: 0.7536\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4629 - accuracy: 0.7501 - val_loss: 0.4648 - val_accuracy: 0.7548\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4616 - accuracy: 0.7526 - val_loss: 0.4615 - val_accuracy: 0.7566\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4578 - accuracy: 0.7598 - val_loss: 0.4572 - val_accuracy: 0.7795\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4540 - accuracy: 0.7818 - val_loss: 0.4546 - val_accuracy: 0.7894\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4498 - accuracy: 0.7947 - val_loss: 0.4528 - val_accuracy: 0.8007\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4483 - accuracy: 0.8039 - val_loss: 0.4512 - val_accuracy: 0.8027\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4467 - accuracy: 0.8076 - val_loss: 0.4476 - val_accuracy: 0.8087\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4432 - accuracy: 0.8119 - val_loss: 0.4484 - val_accuracy: 0.8095\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4422 - accuracy: 0.8122 - val_loss: 0.4520 - val_accuracy: 0.8093\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4421 - accuracy: 0.8117 - val_loss: 0.4566 - val_accuracy: 0.8086\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4443 - accuracy: 0.8121 - val_loss: 0.4472 - val_accuracy: 0.8085\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4424 - accuracy: 0.8129 - val_loss: 0.4505 - val_accuracy: 0.8094\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4442 - accuracy: 0.8138 - val_loss: 0.4556 - val_accuracy: 0.8095\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4470 - accuracy: 0.8145 - val_loss: 0.4554 - val_accuracy: 0.8102\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4485 - accuracy: 0.8151 - val_loss: 0.4554 - val_accuracy: 0.8118\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4481 - accuracy: 0.8156 - val_loss: 0.4624 - val_accuracy: 0.8117\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4525 - accuracy: 0.8164 - val_loss: 0.4606 - val_accuracy: 0.8126\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4525 - accuracy: 0.8171 - val_loss: 0.4660 - val_accuracy: 0.8126\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4540 - accuracy: 0.8178 - val_loss: 0.4658 - val_accuracy: 0.8141\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4550 - accuracy: 0.8188 - val_loss: 0.4719 - val_accuracy: 0.8137\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4586 - accuracy: 0.8186 - val_loss: 0.4717 - val_accuracy: 0.8150\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4607 - accuracy: 0.8195 - val_loss: 0.4724 - val_accuracy: 0.8168\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4621 - accuracy: 0.8211 - val_loss: 0.4773 - val_accuracy: 0.8172\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4644 - accuracy: 0.8212 - val_loss: 0.4792 - val_accuracy: 0.8178\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 18s 42ms/step - loss: 0.4659 - accuracy: 0.8210 - val_loss: 0.4794 - val_accuracy: 0.8189\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4655 - accuracy: 0.8210 - val_loss: 0.4810 - val_accuracy: 0.8190\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4676 - accuracy: 0.8216 - val_loss: 0.4839 - val_accuracy: 0.8195\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4688 - accuracy: 0.8213 - val_loss: 0.4894 - val_accuracy: 0.8198\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4697 - accuracy: 0.8219 - val_loss: 0.4889 - val_accuracy: 0.8203\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4714 - accuracy: 0.8221 - val_loss: 0.4876 - val_accuracy: 0.8207\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4721 - accuracy: 0.8228 - val_loss: 0.4875 - val_accuracy: 0.8205\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4717 - accuracy: 0.8229 - val_loss: 0.4894 - val_accuracy: 0.8204\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4743 - accuracy: 0.8226 - val_loss: 0.4888 - val_accuracy: 0.8217\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4742 - accuracy: 0.8231 - val_loss: 0.4922 - val_accuracy: 0.8205\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4769 - accuracy: 0.8228 - val_loss: 0.4916 - val_accuracy: 0.8211\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4749 - accuracy: 0.8231 - val_loss: 0.4903 - val_accuracy: 0.8212\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4728 - accuracy: 0.8228 - val_loss: 0.4915 - val_accuracy: 0.8212\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4741 - accuracy: 0.8236 - val_loss: 0.4920 - val_accuracy: 0.8205\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4763 - accuracy: 0.8231 - val_loss: 0.4868 - val_accuracy: 0.8192\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4740 - accuracy: 0.8228 - val_loss: 0.4949 - val_accuracy: 0.8207\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4758 - accuracy: 0.8227 - val_loss: 0.4931 - val_accuracy: 0.8200\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4765 - accuracy: 0.8227 - val_loss: 0.4924 - val_accuracy: 0.8199\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4756 - accuracy: 0.8227 - val_loss: 0.4923 - val_accuracy: 0.8201\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4755 - accuracy: 0.8232 - val_loss: 0.4877 - val_accuracy: 0.8200\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4746 - accuracy: 0.8229 - val_loss: 0.4926 - val_accuracy: 0.8202\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  K_NEAREST_NEIGHBORS (with 1790 training and 1790 test examples) achieved an AUC of 0.55 on slice CORRECTLY_CLASSIFIED=False\n",
      "  K_NEAREST_NEIGHBORS (with 1790 training and 1790 test examples) achieved an advantage of 0.10 on slice CORRECTLY_CLASSIFIED=False\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  THRESHOLD_ATTACK (with 20208 training and 9954 test examples) achieved an AUC of 0.50\n",
      "  MULTI_LAYERED_PERCEPTRON (with 9954 training and 9954 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an AUC of 0.50\n",
      "  MULTI_LAYERED_PERCEPTRON (with 7501 training and 7501 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an AUC of 0.53\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an advantage of 0.07\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  RANDOM_FOREST (with 8164 training and 8164 test examples) achieved an AUC of 0.50\n",
      "  RANDOM_FOREST (with 8164 training and 8164 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  K_NEAREST_NEIGHBORS (with 1790 training and 1790 test examples) achieved an AUC of 0.55\n",
      "  K_NEAREST_NEIGHBORS (with 1790 training and 1790 test examples) achieved an advantage of 0.10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 0.5172600554247768 iterated over 21050 steps satisfies differential privacy with eps = 16 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 17s 38ms/step - loss: 0.5420 - accuracy: 0.7381 - val_loss: 0.5018 - val_accuracy: 0.7536\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4960 - accuracy: 0.7499 - val_loss: 0.4839 - val_accuracy: 0.7538\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4782 - accuracy: 0.7499 - val_loss: 0.4753 - val_accuracy: 0.7539\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4694 - accuracy: 0.7535 - val_loss: 0.4677 - val_accuracy: 0.7585\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4590 - accuracy: 0.7604 - val_loss: 0.4593 - val_accuracy: 0.7639\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4490 - accuracy: 0.7794 - val_loss: 0.4548 - val_accuracy: 0.7852\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4427 - accuracy: 0.7942 - val_loss: 0.4456 - val_accuracy: 0.8016\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4352 - accuracy: 0.8086 - val_loss: 0.4398 - val_accuracy: 0.8035\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4330 - accuracy: 0.8114 - val_loss: 0.4384 - val_accuracy: 0.8067\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4317 - accuracy: 0.8142 - val_loss: 0.4480 - val_accuracy: 0.8077\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4341 - accuracy: 0.8142 - val_loss: 0.4522 - val_accuracy: 0.8081\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4421 - accuracy: 0.8147 - val_loss: 0.4565 - val_accuracy: 0.8091\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4465 - accuracy: 0.8155 - val_loss: 0.4617 - val_accuracy: 0.8096\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4525 - accuracy: 0.8154 - val_loss: 0.4684 - val_accuracy: 0.8096\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4589 - accuracy: 0.8158 - val_loss: 0.4729 - val_accuracy: 0.8100\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4633 - accuracy: 0.8164 - val_loss: 0.4750 - val_accuracy: 0.8105\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4653 - accuracy: 0.8165 - val_loss: 0.4800 - val_accuracy: 0.8106\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4679 - accuracy: 0.8173 - val_loss: 0.4855 - val_accuracy: 0.8110\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4703 - accuracy: 0.8176 - val_loss: 0.4816 - val_accuracy: 0.8123\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4709 - accuracy: 0.8184 - val_loss: 0.4802 - val_accuracy: 0.8133\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4710 - accuracy: 0.8194 - val_loss: 0.4825 - val_accuracy: 0.8136\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4708 - accuracy: 0.8197 - val_loss: 0.4883 - val_accuracy: 0.8130\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4732 - accuracy: 0.8195 - val_loss: 0.4853 - val_accuracy: 0.8140\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4722 - accuracy: 0.8204 - val_loss: 0.4874 - val_accuracy: 0.8142\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4730 - accuracy: 0.8214 - val_loss: 0.4883 - val_accuracy: 0.8150\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4749 - accuracy: 0.8213 - val_loss: 0.4906 - val_accuracy: 0.8148\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4734 - accuracy: 0.8225 - val_loss: 0.4885 - val_accuracy: 0.8166\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4735 - accuracy: 0.8232 - val_loss: 0.4902 - val_accuracy: 0.8168\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4740 - accuracy: 0.8228 - val_loss: 0.4861 - val_accuracy: 0.8184\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4728 - accuracy: 0.8233 - val_loss: 0.4891 - val_accuracy: 0.8186\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4738 - accuracy: 0.8233 - val_loss: 0.4912 - val_accuracy: 0.8186\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4738 - accuracy: 0.8236 - val_loss: 0.4915 - val_accuracy: 0.8186\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4734 - accuracy: 0.8241 - val_loss: 0.4895 - val_accuracy: 0.8193\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4734 - accuracy: 0.8240 - val_loss: 0.4916 - val_accuracy: 0.8194\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4734 - accuracy: 0.8238 - val_loss: 0.4942 - val_accuracy: 0.8187\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4742 - accuracy: 0.8239 - val_loss: 0.4887 - val_accuracy: 0.8202\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4720 - accuracy: 0.8239 - val_loss: 0.4911 - val_accuracy: 0.8201\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4724 - accuracy: 0.8239 - val_loss: 0.4886 - val_accuracy: 0.8203\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4714 - accuracy: 0.8239 - val_loss: 0.4900 - val_accuracy: 0.8202\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4714 - accuracy: 0.8241 - val_loss: 0.4892 - val_accuracy: 0.8209\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4731 - accuracy: 0.8244 - val_loss: 0.4903 - val_accuracy: 0.8208\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4730 - accuracy: 0.8243 - val_loss: 0.4882 - val_accuracy: 0.8200\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4728 - accuracy: 0.8242 - val_loss: 0.4901 - val_accuracy: 0.8201\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4730 - accuracy: 0.8250 - val_loss: 0.4935 - val_accuracy: 0.8209\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 15s 37ms/step - loss: 0.4735 - accuracy: 0.8246 - val_loss: 0.4936 - val_accuracy: 0.8209\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4743 - accuracy: 0.8246 - val_loss: 0.4905 - val_accuracy: 0.8204\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4742 - accuracy: 0.8250 - val_loss: 0.4927 - val_accuracy: 0.8202\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4737 - accuracy: 0.8250 - val_loss: 0.4949 - val_accuracy: 0.8207\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4743 - accuracy: 0.8256 - val_loss: 0.4877 - val_accuracy: 0.8192\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4713 - accuracy: 0.8251 - val_loss: 0.4915 - val_accuracy: 0.8202\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an AUC of 0.52 on slice CLASS=1\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an advantage of 0.06 on slice CLASS=1\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  K_NEAREST_NEIGHBORS (with 9954 training and 9954 test examples) achieved an AUC of 0.51\n",
      "  RANDOM_FOREST (with 9954 training and 9954 test examples) achieved an advantage of 0.02\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an AUC of 0.51\n",
      "  RANDOM_FOREST (with 7501 training and 7501 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an AUC of 0.52\n",
      "  LOGISTIC_REGRESSION (with 2453 training and 2453 test examples) achieved an advantage of 0.06\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  K_NEAREST_NEIGHBORS (with 8164 training and 8164 test examples) achieved an AUC of 0.51\n",
      "  RANDOM_FOREST (with 8164 training and 8164 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  THRESHOLD_ATTACK (with 3540 training and 1790 test examples) achieved an AUC of 0.51\n",
      "  LOGISTIC_REGRESSION (with 1790 training and 1790 test examples) achieved an advantage of 0.06\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 0.3320461699705749 iterated over 21050 steps satisfies differential privacy with eps = 100 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 16s 36ms/step - loss: 0.5780 - accuracy: 0.6835 - val_loss: 0.5067 - val_accuracy: 0.7535\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4927 - accuracy: 0.7504 - val_loss: 0.4803 - val_accuracy: 0.7542\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4692 - accuracy: 0.7544 - val_loss: 0.4497 - val_accuracy: 0.7656\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4479 - accuracy: 0.7680 - val_loss: 0.4524 - val_accuracy: 0.7770\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4397 - accuracy: 0.7891 - val_loss: 0.4343 - val_accuracy: 0.7962\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4282 - accuracy: 0.8085 - val_loss: 0.4388 - val_accuracy: 0.8089\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4250 - accuracy: 0.8153 - val_loss: 0.4391 - val_accuracy: 0.8098\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4300 - accuracy: 0.8163 - val_loss: 0.4466 - val_accuracy: 0.8100\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4363 - accuracy: 0.8165 - val_loss: 0.4547 - val_accuracy: 0.8112\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4448 - accuracy: 0.8175 - val_loss: 0.4628 - val_accuracy: 0.8114\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4532 - accuracy: 0.8177 - val_loss: 0.4698 - val_accuracy: 0.8121\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4594 - accuracy: 0.8192 - val_loss: 0.4829 - val_accuracy: 0.8113\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4658 - accuracy: 0.8193 - val_loss: 0.4836 - val_accuracy: 0.8125\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4683 - accuracy: 0.8198 - val_loss: 0.4912 - val_accuracy: 0.8125\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4710 - accuracy: 0.8208 - val_loss: 0.4865 - val_accuracy: 0.8147\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4712 - accuracy: 0.8217 - val_loss: 0.4887 - val_accuracy: 0.8153\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4719 - accuracy: 0.8227 - val_loss: 0.4932 - val_accuracy: 0.8145\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4717 - accuracy: 0.8225 - val_loss: 0.4900 - val_accuracy: 0.8169\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4708 - accuracy: 0.8236 - val_loss: 0.4924 - val_accuracy: 0.8173\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4702 - accuracy: 0.8237 - val_loss: 0.4884 - val_accuracy: 0.8188\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4711 - accuracy: 0.8242 - val_loss: 0.4925 - val_accuracy: 0.8184\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4724 - accuracy: 0.8237 - val_loss: 0.4868 - val_accuracy: 0.8194\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4696 - accuracy: 0.8245 - val_loss: 0.4934 - val_accuracy: 0.8197\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4711 - accuracy: 0.8243 - val_loss: 0.4892 - val_accuracy: 0.8195\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4702 - accuracy: 0.8250 - val_loss: 0.4884 - val_accuracy: 0.8201\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4699 - accuracy: 0.8252 - val_loss: 0.4933 - val_accuracy: 0.8203\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4698 - accuracy: 0.8257 - val_loss: 0.4878 - val_accuracy: 0.8208\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4698 - accuracy: 0.8254 - val_loss: 0.4956 - val_accuracy: 0.8206\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4710 - accuracy: 0.8262 - val_loss: 0.4903 - val_accuracy: 0.8207\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4716 - accuracy: 0.8256 - val_loss: 0.4935 - val_accuracy: 0.8218\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4706 - accuracy: 0.8258 - val_loss: 0.4848 - val_accuracy: 0.8203\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4689 - accuracy: 0.8264 - val_loss: 0.4899 - val_accuracy: 0.8219\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4693 - accuracy: 0.8268 - val_loss: 0.4899 - val_accuracy: 0.8214\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4716 - accuracy: 0.8271 - val_loss: 0.4926 - val_accuracy: 0.8225\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4702 - accuracy: 0.8268 - val_loss: 0.4890 - val_accuracy: 0.8219\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4685 - accuracy: 0.8269 - val_loss: 0.4881 - val_accuracy: 0.8216\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4683 - accuracy: 0.8274 - val_loss: 0.4861 - val_accuracy: 0.8216\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4669 - accuracy: 0.8274 - val_loss: 0.4863 - val_accuracy: 0.8216\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4678 - accuracy: 0.8276 - val_loss: 0.4857 - val_accuracy: 0.8218\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4674 - accuracy: 0.8278 - val_loss: 0.4895 - val_accuracy: 0.8226\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 15s 35ms/step - loss: 0.4679 - accuracy: 0.8275 - val_loss: 0.4796 - val_accuracy: 0.8212\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 15s 36ms/step - loss: 0.4652 - accuracy: 0.8282 - val_loss: 0.4903 - val_accuracy: 0.8232\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 16s 39ms/step - loss: 0.4683 - accuracy: 0.8275 - val_loss: 0.4851 - val_accuracy: 0.8226\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4666 - accuracy: 0.8280 - val_loss: 0.4848 - val_accuracy: 0.8224\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4661 - accuracy: 0.8281 - val_loss: 0.4867 - val_accuracy: 0.8229\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4669 - accuracy: 0.8283 - val_loss: 0.4859 - val_accuracy: 0.8239\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 16s 37ms/step - loss: 0.4664 - accuracy: 0.8286 - val_loss: 0.4888 - val_accuracy: 0.8235\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4664 - accuracy: 0.8287 - val_loss: 0.4916 - val_accuracy: 0.8246\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4658 - accuracy: 0.8288 - val_loss: 0.4855 - val_accuracy: 0.8236\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 16s 38ms/step - loss: 0.4647 - accuracy: 0.8294 - val_loss: 0.4847 - val_accuracy: 0.8235\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  LOGISTIC_REGRESSION (with 8197 training and 8197 test examples) achieved an AUC of 0.52 on slice CORRECTLY_CLASSIFIED=True\n",
      "  LOGISTIC_REGRESSION (with 1757 training and 1757 test examples) achieved an advantage of 0.07 on slice CORRECTLY_CLASSIFIED=False\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  LOGISTIC_REGRESSION (with 9954 training and 9954 test examples) achieved an AUC of 0.51\n",
      "  MULTI_LAYERED_PERCEPTRON (with 9954 training and 9954 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  LOGISTIC_REGRESSION (with 7501 training and 7501 test examples) achieved an AUC of 0.52\n",
      "  MULTI_LAYERED_PERCEPTRON (with 7501 training and 7501 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  THRESHOLD_ATTACK (with 5055 training and 2453 test examples) achieved an AUC of 0.52\n",
      "  MULTI_LAYERED_PERCEPTRON (with 2453 training and 2453 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  LOGISTIC_REGRESSION (with 8197 training and 8197 test examples) achieved an AUC of 0.52\n",
      "  LOGISTIC_REGRESSION (with 8197 training and 8197 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  K_NEAREST_NEIGHBORS (with 1757 training and 1757 test examples) achieved an AUC of 0.52\n",
      "  LOGISTIC_REGRESSION (with 1757 training and 1757 test examples) achieved an advantage of 0.07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 0.21836654222821442 iterated over 21050 steps satisfies differential privacy with eps = 1e+03 and delta = 1e-06.\n",
      "Epoch 1/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.5589 - accuracy: 0.7027 - val_loss: 0.4776 - val_accuracy: 0.7538\n",
      "Epoch 2/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4647 - accuracy: 0.7553 - val_loss: 0.4630 - val_accuracy: 0.7646\n",
      "Epoch 3/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4527 - accuracy: 0.7745 - val_loss: 0.4504 - val_accuracy: 0.7872\n",
      "Epoch 4/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4412 - accuracy: 0.7991 - val_loss: 0.4474 - val_accuracy: 0.8076\n",
      "Epoch 5/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4362 - accuracy: 0.8129 - val_loss: 0.4511 - val_accuracy: 0.8077\n",
      "Epoch 6/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4391 - accuracy: 0.8145 - val_loss: 0.4472 - val_accuracy: 0.8080\n",
      "Epoch 7/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4472 - accuracy: 0.8163 - val_loss: 0.4648 - val_accuracy: 0.8091\n",
      "Epoch 8/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4555 - accuracy: 0.8166 - val_loss: 0.4668 - val_accuracy: 0.8091\n",
      "Epoch 9/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4612 - accuracy: 0.8166 - val_loss: 0.4783 - val_accuracy: 0.8093\n",
      "Epoch 10/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4655 - accuracy: 0.8159 - val_loss: 0.4796 - val_accuracy: 0.8097\n",
      "Epoch 11/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4687 - accuracy: 0.8173 - val_loss: 0.4872 - val_accuracy: 0.8098\n",
      "Epoch 12/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4694 - accuracy: 0.8178 - val_loss: 0.4850 - val_accuracy: 0.8118\n",
      "Epoch 13/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4712 - accuracy: 0.8189 - val_loss: 0.4845 - val_accuracy: 0.8127\n",
      "Epoch 14/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4699 - accuracy: 0.8203 - val_loss: 0.4805 - val_accuracy: 0.8160\n",
      "Epoch 15/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4703 - accuracy: 0.8217 - val_loss: 0.4851 - val_accuracy: 0.8153\n",
      "Epoch 16/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4697 - accuracy: 0.8235 - val_loss: 0.4860 - val_accuracy: 0.8164\n",
      "Epoch 17/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4703 - accuracy: 0.8230 - val_loss: 0.4821 - val_accuracy: 0.8188\n",
      "Epoch 18/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4689 - accuracy: 0.8241 - val_loss: 0.4839 - val_accuracy: 0.8190\n",
      "Epoch 19/50\n",
      "421/421 [==============================] - 18s 42ms/step - loss: 0.4702 - accuracy: 0.8242 - val_loss: 0.4799 - val_accuracy: 0.8199\n",
      "Epoch 20/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4677 - accuracy: 0.8249 - val_loss: 0.4749 - val_accuracy: 0.8202\n",
      "Epoch 21/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4665 - accuracy: 0.8246 - val_loss: 0.4800 - val_accuracy: 0.8205\n",
      "Epoch 22/50\n",
      "421/421 [==============================] - 18s 42ms/step - loss: 0.4666 - accuracy: 0.8249 - val_loss: 0.4817 - val_accuracy: 0.8211\n",
      "Epoch 23/50\n",
      "421/421 [==============================] - 17s 42ms/step - loss: 0.4670 - accuracy: 0.8250 - val_loss: 0.4838 - val_accuracy: 0.8204\n",
      "Epoch 24/50\n",
      "421/421 [==============================] - 18s 42ms/step - loss: 0.4671 - accuracy: 0.8249 - val_loss: 0.4799 - val_accuracy: 0.8215\n",
      "Epoch 25/50\n",
      "421/421 [==============================] - 18s 42ms/step - loss: 0.4658 - accuracy: 0.8254 - val_loss: 0.4874 - val_accuracy: 0.8205\n",
      "Epoch 26/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4671 - accuracy: 0.8255 - val_loss: 0.4779 - val_accuracy: 0.8213\n",
      "Epoch 27/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4660 - accuracy: 0.8265 - val_loss: 0.4816 - val_accuracy: 0.8213\n",
      "Epoch 28/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4652 - accuracy: 0.8261 - val_loss: 0.4861 - val_accuracy: 0.8217\n",
      "Epoch 29/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4653 - accuracy: 0.8261 - val_loss: 0.4859 - val_accuracy: 0.8220\n",
      "Epoch 30/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4655 - accuracy: 0.8263 - val_loss: 0.4847 - val_accuracy: 0.8227\n",
      "Epoch 31/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4649 - accuracy: 0.8263 - val_loss: 0.4806 - val_accuracy: 0.8220\n",
      "Epoch 32/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4646 - accuracy: 0.8270 - val_loss: 0.4874 - val_accuracy: 0.8230\n",
      "Epoch 33/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4643 - accuracy: 0.8276 - val_loss: 0.4841 - val_accuracy: 0.8229\n",
      "Epoch 34/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4648 - accuracy: 0.8275 - val_loss: 0.4827 - val_accuracy: 0.8229\n",
      "Epoch 35/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4630 - accuracy: 0.8273 - val_loss: 0.4779 - val_accuracy: 0.8227\n",
      "Epoch 36/50\n",
      "421/421 [==============================] - 17s 41ms/step - loss: 0.4624 - accuracy: 0.8284 - val_loss: 0.4850 - val_accuracy: 0.8234\n",
      "Epoch 37/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4640 - accuracy: 0.8281 - val_loss: 0.4815 - val_accuracy: 0.8237\n",
      "Epoch 38/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4628 - accuracy: 0.8283 - val_loss: 0.4775 - val_accuracy: 0.8236\n",
      "Epoch 39/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4611 - accuracy: 0.8287 - val_loss: 0.4815 - val_accuracy: 0.8241\n",
      "Epoch 40/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4624 - accuracy: 0.8294 - val_loss: 0.4828 - val_accuracy: 0.8246\n",
      "Epoch 41/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4647 - accuracy: 0.8290 - val_loss: 0.4841 - val_accuracy: 0.8254\n",
      "Epoch 42/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4629 - accuracy: 0.8299 - val_loss: 0.4808 - val_accuracy: 0.8259\n",
      "Epoch 43/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4626 - accuracy: 0.8295 - val_loss: 0.4799 - val_accuracy: 0.8260\n",
      "Epoch 44/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4615 - accuracy: 0.8302 - val_loss: 0.4840 - val_accuracy: 0.8261\n",
      "Epoch 45/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4618 - accuracy: 0.8302 - val_loss: 0.4808 - val_accuracy: 0.8268\n",
      "Epoch 46/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4628 - accuracy: 0.8304 - val_loss: 0.4778 - val_accuracy: 0.8281\n",
      "Epoch 47/50\n",
      "421/421 [==============================] - 18s 42ms/step - loss: 0.4593 - accuracy: 0.8316 - val_loss: 0.4805 - val_accuracy: 0.8280\n",
      "Epoch 48/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4619 - accuracy: 0.8309 - val_loss: 0.4810 - val_accuracy: 0.8282\n",
      "Epoch 49/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4592 - accuracy: 0.8315 - val_loss: 0.4834 - val_accuracy: 0.8277\n",
      "Epoch 50/50\n",
      "421/421 [==============================] - 17s 40ms/step - loss: 0.4594 - accuracy: 0.8319 - val_loss: 0.4783 - val_accuracy: 0.8283\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n",
      "Best-performing attacks over all slices\n",
      "  RANDOM_FOREST (with 1709 training and 1709 test examples) achieved an AUC of 0.52 on slice CORRECTLY_CLASSIFIED=False\n",
      "  RANDOM_FOREST (with 2453 training and 2453 test examples) achieved an advantage of 0.08 on slice CLASS=1\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  LOGISTIC_REGRESSION (with 9954 training and 9954 test examples) achieved an AUC of 0.51\n",
      "  LOGISTIC_REGRESSION (with 9954 training and 9954 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  THRESHOLD_ATTACK (with 15153 training and 7501 test examples) achieved an AUC of 0.50\n",
      "  K_NEAREST_NEIGHBORS (with 7501 training and 7501 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  THRESHOLD_ATTACK (with 5055 training and 2453 test examples) achieved an AUC of 0.52\n",
      "  RANDOM_FOREST (with 2453 training and 2453 test examples) achieved an advantage of 0.08\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  LOGISTIC_REGRESSION (with 8245 training and 8245 test examples) achieved an AUC of 0.52\n",
      "  LOGISTIC_REGRESSION (with 8245 training and 8245 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  RANDOM_FOREST (with 1709 training and 1709 test examples) achieved an AUC of 0.52\n",
      "  LOGISTIC_REGRESSION (with 1709 training and 1709 test examples) achieved an advantage of 0.05\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "========================================\n",
      "Epochs, Target epsilon, delta, C, Sigma, Sampling rate, Epsilon, Loss, Val loss, Accuracy, Val accuracy, Time, AUC, Advantage\n",
      "50, 0.01, 1e-06, 2.5, 17994.001391472444, 0.0023752969121140144, 0, 0.7798415422439575, 0.7803100943565369, 0.2673198878765106, 0.26029735803604126, 759.0008347034454, 0.5253518123667378, 0.07423043609949465\n",
      "50, 0.1, 1e-06, 2.5, 14.309830337352679, 0.0023752969121140144, 0.11208687744399892, 0.4863673448562622, 0.4875877797603607, 0.7498515248298645, 0.7535663843154907, 774.4385318756104, 0.5437999160427438, 0.08373142180019238\n",
      "50, 0.5, 1e-06, 2.5, 3.0864306316599435, 0.0023752969121140144, 0.5000000000000254, 0.44302308559417725, 0.4543653428554535, 0.8076504468917847, 0.8016877770423889, 784.9998731613159, 0.5400670110288985, 0.07836430677254846\n",
      "50, 1, 1e-06, 2.5, 1.7217127690788603, 0.0023752969121140144, 0.9999999999996306, 0.4501935541629791, 0.46728575229644775, 0.8186856508255005, 0.8090214729309082, 741.9407825469971, 0.5186605629387165, 0.08210010042988242\n",
      "50, 2, 1e-06, 2.5, 1.0674083630051678, 0.0023752969121140144, 2.0000000000002136, 0.4724132716655731, 0.4828910529613495, 0.8225455284118652, 0.8190677165985107, 781.4327447414398, 0.5312023423011727, 0.07745750184774576\n",
      "50, 4, 1e-06, 2.5, 0.7767693318298682, 0.0023752969121140144, 3.996933447631479, 0.47287458181381226, 0.4919905364513397, 0.8201207518577576, 0.8132408857345581, 790.2227935791016, 0.5268184982278643, 0.062365591397849446\n",
      "50, 8, 1e-06, 2.5, 0.6223068197048801, 0.0023752969121140144, 7.9999999999648965, 0.4746285080909729, 0.4925975501537323, 0.8228919506072998, 0.8201727867126465, 850.1633591651917, 0.5507026006711409, 0.09936780920421862\n",
      "50, 16, 1e-06, 2.5, 0.5172600554247768, 0.0023752969121140144, 15.922549536071656, 0.47129902243614197, 0.49150311946868896, 0.8250693082809448, 0.8201727867126465, 778.4272150993347, 0.5220414366255559, 0.06107890387956916\n",
      "50, 100, 1e-06, 2.5, 0.3320461699705749, 0.0023752969121140144, 97.44082691565612, 0.4647347629070282, 0.4846911132335663, 0.8294239640235901, 0.8234880566596985, 754.5064980983734, 0.5184126700710638, 0.07101884448125906\n",
      "50, 1000, 1e-06, 2.5, 0.21836654222821442, 0.0023752969121140144, 484.87516825758695, 0.4594428241252899, 0.47825297713279724, 0.8318982720375061, 0.8283102512359619, 854.4541156291962, 0.5179364836175009, 0.07952824524020807\n"
     ]
    }
   ],
   "source": [
    "# TEST FOR DIFFERENT EPS\n",
    "results_summary = []\n",
    "\n",
    "n = X_train.shape[0]\n",
    "epochs = 50\n",
    "batch_size = 48\n",
    "microbatches = 48\n",
    "epsilons = [0.1,0.5,1,2,4,8,16,100,1000]\n",
    "delta = 1e-6\n",
    "min_noise = 1e-100\n",
    "l2_norm_clip = 2.5\n",
    "sampling_rate = batch_size / n\n",
    "attacks = 1\n",
    "\n",
    "for e in epsilons:\n",
    "    # Compute noise multiplier from target epsilon\n",
    "    noise_multiplier = compute_noise(n, batch_size, e, epochs, delta, min_noise)\n",
    "    \n",
    "    # Compute epsilon\n",
    "    orders = [1 + x / 10. for x in range(1, 100)] + list(range(11, 101))\n",
    "    sampling_probability = batch_size / n\n",
    "    rdp = compute_rdp(q=sampling_probability,\n",
    "                    noise_multiplier=noise_multiplier,\n",
    "                    steps=epochs * n // batch_size,\n",
    "                    orders=orders)\n",
    "    eps = get_privacy_spent(orders, rdp, target_delta=delta)\n",
    "\n",
    "    # Instantiate network\n",
    "    model = create_dp_nn(noise_multiplier, l2_norm_clip, microbatches)\n",
    "\n",
    "    # Train network\n",
    "    start_time = time.time()\n",
    "    r = model.fit(X_train, \n",
    "                 y_train, \n",
    "                 validation_data=(X_test, y_test), \n",
    "                 epochs=epochs, \n",
    "                 batch_size=batch_size,\n",
    "                 #callbacks=[callback]\n",
    "                )\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "\n",
    "    # MIA \n",
    "    aauc = []\n",
    "    aadv = []\n",
    "    for _ in range(attacks):\n",
    "        auc, adv = membership_inference_attack(model, X_train, X_test, y_train, y_test)\n",
    "        aauc.append(auc)\n",
    "        aadv.append(adv)\n",
    "    mauc = sum(aauc) / attacks\n",
    "    madv = sum(aadv) / attacks\n",
    "\n",
    "    # Write result summary\n",
    "    summ = ', '.join(map(str,[\n",
    "          len(r.history['loss']),\n",
    "          e,\n",
    "          delta,\n",
    "          l2_norm_clip,\n",
    "          noise_multiplier,\n",
    "          sampling_rate,\n",
    "          eps[0],\n",
    "          r.history['loss'][-1], \n",
    "          r.history['val_loss'][-1],\n",
    "          r.history['accuracy'][-1],\n",
    "          r.history['val_accuracy'][-1],\n",
    "          time_elapsed,\n",
    "          mauc,\n",
    "          madv\n",
    "    ]))\n",
    "    results_summary.append(summ)\n",
    "    print('='*40)\n",
    "\n",
    "    \n",
    "print('Epochs, Target epsilon, delta, C, Sigma, Sampling rate, Epsilon, Loss, Val loss, Accuracy, Val accuracy, Time, AUC, Advantage')\n",
    "for r in results_summary:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "52e98939",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.238% and noise_multiplier = 0.21836654222821442 iterated over 21050 steps satisfies differential privacy with eps = 1e+03 and delta = 1e-06.\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "math domain error",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-73-989fd0163348>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0morders\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlinspace\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m101\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m1000\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0msampling_probability\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_size\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m rdp = compute_rdp(q=sampling_probability,\n\u001b[0m\u001b[0;32m      5\u001b[0m                     \u001b[0mnoise_multiplier\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnoise_multiplier\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m                     \u001b[0msteps\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m \u001b[1;33m*\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m//\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_privacy\\privacy\\analysis\\rdp_accountant.py\u001b[0m in \u001b[0;36mcompute_rdp\u001b[1;34m(q, noise_multiplier, steps, orders)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[0mrdp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compute_rdp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_multiplier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m     rdp = np.array([_compute_rdp(q, noise_multiplier, order)\n\u001b[0m\u001b[0;32m    392\u001b[0m                     for order in orders])\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_privacy\\privacy\\analysis\\rdp_accountant.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    389\u001b[0m     \u001b[0mrdp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_compute_rdp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnoise_multiplier\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morders\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    390\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 391\u001b[1;33m     rdp = np.array([_compute_rdp(q, noise_multiplier, order)\n\u001b[0m\u001b[0;32m    392\u001b[0m                     for order in orders])\n\u001b[0;32m    393\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_privacy\\privacy\\analysis\\rdp_accountant.py\u001b[0m in \u001b[0;36m_compute_rdp\u001b[1;34m(q, sigma, alpha)\u001b[0m\n\u001b[0;32m    370\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minf\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    371\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 372\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_log_a\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m/\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m \u001b[1;33m-\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    373\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    374\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_privacy\\privacy\\analysis\\rdp_accountant.py\u001b[0m in \u001b[0;36m_compute_log_a\u001b[1;34m(q, sigma, alpha)\u001b[0m\n\u001b[0;32m    166\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_log_a_int\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    167\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 168\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_compute_log_a_frac\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mq\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msigma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    169\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    170\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow_privacy\\privacy\\analysis\\rdp_accountant.py\u001b[0m in \u001b[0;36m_compute_log_a_frac\u001b[1;34m(q, sigma, alpha)\u001b[0m\n\u001b[0;32m    135\u001b[0m   \u001b[1;32mwhile\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# do ... until loop\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m     \u001b[0mcoef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspecial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbinom\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0malpha\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 137\u001b[1;33m     \u001b[0mlog_coef\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcoef\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    138\u001b[0m     \u001b[0mj\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0malpha\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    139\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: math domain error"
     ]
    }
   ],
   "source": [
    "noise_multiplier = compute_noise(n, batch_size, 1000, epochs, delta, min_noise)\n",
    "orders = np.arange(1.1,10,0.1) + np.arange()\n",
    "sampling_probability = batch_size / n\n",
    "rdp = compute_rdp(q=sampling_probability,\n",
    "                    noise_multiplier=noise_multiplier,\n",
    "                    steps=epochs * n // batch_size,\n",
    "                    orders=orders)\n",
    "get_privacy_spent(orders, rdp, target_delta=delta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "6d0d2f22",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.1,\n",
       " 1.2000000000000002,\n",
       " 1.3000000000000003,\n",
       " 1.4000000000000004,\n",
       " 1.5000000000000004,\n",
       " 1.6000000000000005,\n",
       " 1.7000000000000006,\n",
       " 1.8000000000000007,\n",
       " 1.9000000000000008,\n",
       " 2.000000000000001,\n",
       " 2.100000000000001,\n",
       " 2.200000000000001,\n",
       " 2.300000000000001,\n",
       " 2.4000000000000012,\n",
       " 2.5000000000000013,\n",
       " 2.6000000000000014,\n",
       " 2.7000000000000015,\n",
       " 2.8000000000000016,\n",
       " 2.9000000000000017,\n",
       " 3.0000000000000018,\n",
       " 3.100000000000002,\n",
       " 3.200000000000002,\n",
       " 3.300000000000002,\n",
       " 3.400000000000002,\n",
       " 3.500000000000002,\n",
       " 3.6000000000000023,\n",
       " 3.7000000000000024,\n",
       " 3.8000000000000025,\n",
       " 3.9000000000000026,\n",
       " 4.000000000000003,\n",
       " 4.100000000000003,\n",
       " 4.200000000000003,\n",
       " 4.3000000000000025,\n",
       " 4.400000000000003,\n",
       " 4.5000000000000036,\n",
       " 4.600000000000003,\n",
       " 4.700000000000003,\n",
       " 4.800000000000003,\n",
       " 4.900000000000004,\n",
       " 5.0000000000000036,\n",
       " 5.100000000000003,\n",
       " 5.200000000000003,\n",
       " 5.300000000000004,\n",
       " 5.400000000000004,\n",
       " 5.5000000000000036,\n",
       " 5.600000000000003,\n",
       " 5.700000000000005,\n",
       " 5.800000000000004,\n",
       " 5.900000000000004,\n",
       " 6.0000000000000036,\n",
       " 6.100000000000005,\n",
       " 6.200000000000005,\n",
       " 6.300000000000004,\n",
       " 6.400000000000004,\n",
       " 6.500000000000005,\n",
       " 6.600000000000005,\n",
       " 6.700000000000005,\n",
       " 6.800000000000004,\n",
       " 6.900000000000006,\n",
       " 7.000000000000005,\n",
       " 7.100000000000005,\n",
       " 7.200000000000005,\n",
       " 7.300000000000006,\n",
       " 7.400000000000006,\n",
       " 7.500000000000005,\n",
       " 7.600000000000005,\n",
       " 7.700000000000006,\n",
       " 7.800000000000006,\n",
       " 7.900000000000006,\n",
       " 8.000000000000005,\n",
       " 8.100000000000007,\n",
       " 8.200000000000006,\n",
       " 8.300000000000006,\n",
       " 8.400000000000006,\n",
       " 8.500000000000007,\n",
       " 8.600000000000007,\n",
       " 8.700000000000006,\n",
       " 8.800000000000006,\n",
       " 8.900000000000007,\n",
       " 9.000000000000007,\n",
       " 9.100000000000007,\n",
       " 9.200000000000006,\n",
       " 9.300000000000006,\n",
       " 9.400000000000007,\n",
       " 9.500000000000007,\n",
       " 9.600000000000007,\n",
       " 9.700000000000008,\n",
       " 9.800000000000008,\n",
       " 9.900000000000007]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "orders = list(np.arange(1.1,10,0.1))\n",
    "orders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4ff31fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 10\n",
    "1ei"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99e732a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
