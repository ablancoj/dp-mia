{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3965e6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import applications\n",
    "from tensorflow.keras.layers import Input, InputLayer, Conv2D, Dense, Lambda, Flatten, Dropout, MaxPooling2D, BatchNormalization, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "from tensorflow.keras.callbacks import Callback, EarlyStopping\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import compute_rdp\n",
    "from tensorflow_privacy.privacy.analysis.rdp_accountant import get_privacy_spent\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras import DPKerasAdamOptimizer\n",
    "from tensorflow_privacy.privacy.optimizers.dp_optimizer_keras_vectorized import VectorizedDPKerasAdamOptimizer\n",
    "from tensorflow_privacy.privacy.analysis.compute_noise_from_budget_lib import compute_noise\n",
    "from tensorflow_privacy.privacy.keras_models.dp_keras_model import DPSequential\n",
    "\n",
    "\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack import membership_inference_attack as mia\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackInputData\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import SlicingSpec\n",
    "from tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.data_structures import AttackType\n",
    "\n",
    "import tensorflow_privacy.privacy.privacy_tests.membership_inference_attack.plotting as plotting\n",
    "\n",
    "import numpy as np\n",
    "from scipy import special\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9e4d5766",
   "metadata": {},
   "outputs": [],
   "source": [
    "learning_rate = 15e-5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "7336b287",
   "metadata": {},
   "outputs": [],
   "source": [
    "def membership_inference_attack(model, X_train, X_test, y_train, y_test):\n",
    "    print('Predict on train...')\n",
    "    logits_train = model.predict(X_train, batch_size=batch_size)\n",
    "    print('Predict on test...')\n",
    "    logits_test = model.predict(X_test, batch_size=batch_size)\n",
    "\n",
    "    print('Apply softmax to get probabilities from logits...')\n",
    "    prob_train = special.softmax(logits_train, axis=1)\n",
    "    prob_test = special.softmax(logits_test, axis=1)\n",
    "\n",
    "    print('Compute losses...')\n",
    "    cce = tf.keras.backend.categorical_crossentropy\n",
    "    constant = tf.keras.backend.constant\n",
    "\n",
    "    loss_train = cce(constant(y_train), constant(prob_train), from_logits=False).numpy()\n",
    "    loss_test = cce(constant(y_test), constant(prob_test), from_logits=False).numpy()\n",
    "    \n",
    "    labels_train = np.argmax(y_train, axis=1)\n",
    "    labels_test = np.argmax(y_test, axis=1)\n",
    "\n",
    "    input = AttackInputData(\n",
    "      logits_train = logits_train,\n",
    "      logits_test = logits_test,\n",
    "      loss_train = loss_train,\n",
    "      loss_test = loss_test,\n",
    "      labels_train = labels_train,\n",
    "      labels_test = labels_test\n",
    "    )\n",
    "\n",
    "    # Run several attacks for different data slices\n",
    "    attacks_result = mia.run_attacks(input,\n",
    "                                     SlicingSpec(\n",
    "                                         entire_dataset = True,\n",
    "                                         by_class = True,\n",
    "                                         by_classification_correctness = True\n",
    "                                     ),\n",
    "                                     attack_types = [\n",
    "                                         AttackType.THRESHOLD_ATTACK,\n",
    "                                         AttackType.LOGISTIC_REGRESSION\n",
    "                                     ])\n",
    "\n",
    "    # Plot the ROC curve of the best classifier\n",
    "#     fig = plotting.plot_roc_curve(\n",
    "#         attacks_result.get_result_with_max_auc().roc_curve)\n",
    "\n",
    "    # Print a user-friendly summary of the attacks\n",
    "    print(attacks_result.summary(by_slices = True))\n",
    "    time.sleep(5)\n",
    "    return attacks_result.get_result_with_max_auc().get_auc(), attacks_result.get_result_with_max_attacker_advantage().get_attacker_advantage()\n",
    "\n",
    "callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2daea1b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load in the data\n",
    "cifar10 = tf.keras.datasets.cifar10\n",
    "cifar10_categories = ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n",
    "(X_train, y_train_), (X_test, y_test_) = cifar10.load_data()\n",
    "X_train, X_test = X_train.reshape((X_train.shape[0], 32, 32, 3)), X_test.reshape((X_test.shape[0], 32, 32, 3))\n",
    "X_train_flat, X_test_flat = X_train.reshape(-1, 32*32*3), X_test.reshape(-1, 32*32*3)\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "y_train, y_test = np.eye(10)[y_train_.flatten()], np.eye(10)[y_test_.flatten()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fa85c1c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(dropout=None, regularizer=None):\n",
    "    input_data = Input(shape = X_train[0].shape)\n",
    "    \n",
    "    x = Conv2D(20, (5,5), activation=\"relu\")(input_data)\n",
    "    x = MaxPooling2D()(x)\n",
    "    if dropout is not None:\n",
    "        x = Dropout(dropout)(x)\n",
    "    x = Conv2D(50, (5,5), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    if dropout is not None:\n",
    "        x = Dropout(dropout)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(500, activation=\"relu\", kernel_regularizer=regularizer)(x)\n",
    "    if dropout is not None:\n",
    "        x = Dropout(dropout)(x)\n",
    "    output = Dense(10)(x)\n",
    "\n",
    "    model = Model(input_data, output)\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True)\n",
    "            \n",
    "    model.compile(optimizer='adam', loss=loss, metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "def create_dp_cnn(noise_multiplier, l2_norm_clip, microbatches):\n",
    "    input_data = Input(shape = X_train[0].shape)\n",
    "    x = Conv2D(20, (5,5), activation=\"relu\")(input_data)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Conv2D(50, (5,5), activation=\"relu\")(x)\n",
    "    x = MaxPooling2D()(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(500, activation=\"relu\")(x)\n",
    "    output = Dense(10)(x)\n",
    "    \n",
    "    model = Model(input_data, output)\n",
    "    \n",
    "    optimizer = DPKerasAdamOptimizer(\n",
    "                            l2_norm_clip=l2_norm_clip,\n",
    "                            noise_multiplier=noise_multiplier,\n",
    "                            num_microbatches=microbatches,\n",
    "                            learning_rate=learning_rate)\n",
    "    \n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(from_logits=True, reduction=tf.losses.Reduction.NONE)\n",
    "    \n",
    "    model.compile(optimizer=optimizer,\n",
    "              loss=loss,\n",
    "              metrics=['accuracy'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef7f0824",
   "metadata": {},
   "source": [
    "# Baseline & anti-overfitting experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8a0b5777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "457/500 [==========================>...] - ETA: 0s - loss: 1.5444 - accuracy: 0.4434"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-6581d490b6af>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     20\u001b[0m     \u001b[1;31m# Train network until convergence\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     21\u001b[0m     \u001b[0mstart_time\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 22\u001b[1;33m     r = model.fit(X_train, \n\u001b[0m\u001b[0;32m     23\u001b[0m                 \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m                 \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     62\u001b[0m     \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 64\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1219\u001b[0m               \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtmp_logs\u001b[0m  \u001b[1;31m# No error, now safe to assign to logs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1220\u001b[0m               \u001b[0mend_step\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstep\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mdata_handler\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstep_increment\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1221\u001b[1;33m               \u001b[0mcallbacks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mend_step\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1222\u001b[0m               \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mstop_training\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m                 \u001b[1;32mbreak\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m    435\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_should_call_train_batch_hooks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 436\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    437\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    438\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_begin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook\u001b[1;34m(self, mode, hook, batch, logs)\u001b[0m\n\u001b[0;32m    293\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_begin_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    294\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mhook\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;34m'end'\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 295\u001b[1;33m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_end_hook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmode\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    296\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    297\u001b[0m       raise ValueError(\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_end_hook\u001b[1;34m(self, mode, batch, logs)\u001b[0m\n\u001b[0;32m    314\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_time\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    315\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 316\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_batch_hook_helper\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mhook_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    317\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    318\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_times\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m>=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_num_batches_for_timing_check\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_call_batch_hook_helper\u001b[1;34m(self, hook_name, batch, logs)\u001b[0m\n\u001b[0;32m    352\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mcallback\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    353\u001b[0m       \u001b[0mhook\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcallback\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhook_name\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 354\u001b[1;33m       \u001b[0mhook\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    355\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    356\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_check_timing\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36mon_train_batch_end\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1031\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_train_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1032\u001b[1;33m     \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_batch_update_progbar\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1033\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1034\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mon_test_batch_end\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlogs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\callbacks.py\u001b[0m in \u001b[0;36m_batch_update_progbar\u001b[1;34m(self, batch, logs)\u001b[0m\n\u001b[0;32m   1102\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mverbose\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1103\u001b[0m       \u001b[1;31m# Only block async when verbose = 1.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1104\u001b[1;33m       \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1105\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprogbar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseen\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfinalize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1106\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36msync_to_numpy_or_python_type\u001b[1;34m(tensors)\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    553\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 554\u001b[1;33m   \u001b[1;32mreturn\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnest\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmap_structure\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtensors\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    555\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    556\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36mmap_structure\u001b[1;34m(func, *structure, **kwargs)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\util\\nest.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    867\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    868\u001b[0m   return pack_sequence_as(\n\u001b[1;32m--> 869\u001b[1;33m       \u001b[0mstructure\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mentries\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    870\u001b[0m       expand_composites=expand_composites)\n\u001b[0;32m    871\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\keras\\utils\\tf_utils.py\u001b[0m in \u001b[0;36m_to_single_numpy_or_python_type\u001b[1;34m(t)\u001b[0m\n\u001b[0;32m    548\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_to_single_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    549\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 550\u001b[1;33m       \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    551\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m0\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    552\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mt\u001b[0m  \u001b[1;31m# Don't turn ragged or sparse tensors to NumPy.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36mnumpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1147\u001b[0m     \"\"\"\n\u001b[0;32m   1148\u001b[0m     \u001b[1;31m# TODO(slebedev): Consider avoiding a copy for non-CPU or remote tensors.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1149\u001b[1;33m     \u001b[0mmaybe_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1150\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmaybe_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32melse\u001b[0m \u001b[0mmaybe_arr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\u001b[0m in \u001b[0;36m_numpy\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1113\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_numpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1114\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1115\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_numpy_internal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1116\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1117\u001b[0m       \u001b[1;32mraise\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_status_to_exception\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "epochs = 50\n",
    "batch_size = 100\n",
    "attacks = 1\n",
    "settings = [\n",
    "    (None,None),\n",
    "    (0.25,None),\n",
    "    (0.50,None),\n",
    "    (0.75,None),\n",
    "    (None,'l2'),\n",
    "    (0.25,'l2'),\n",
    "    (0.50,'l2'),\n",
    "    (0.75,'l2'),\n",
    "]\n",
    "results_summary = []\n",
    "\n",
    "for drop, reg in settings:\n",
    "    # Instantiate network\n",
    "    model = create_cnn(dropout=drop, regularizer=reg)\n",
    "    \n",
    "    # Train network until convergence\n",
    "    start_time = time.time()\n",
    "    r = model.fit(X_train, \n",
    "                y_train, \n",
    "                validation_data=(X_test, y_test),\n",
    "                epochs=epochs, \n",
    "                batch_size=batch_size\n",
    "               )\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "\n",
    "    # MIA\n",
    "    aauc = []\n",
    "    aadv = []\n",
    "    for _ in range(attacks):\n",
    "        auc, adv = membership_inference_attack(model, X_train, X_test, y_train, y_test)\n",
    "        aauc.append(auc)\n",
    "        aadv.append(adv)\n",
    "    mauc = sum(aauc) / attacks\n",
    "    madv = sum(aadv) / attacks\n",
    "\n",
    "    # Write result summary\n",
    "    summ = ', '.join(map(str,[\n",
    "        len(r.history['loss']), #epochs\n",
    "        drop,\n",
    "        reg,\n",
    "        r.history['loss'][-1], \n",
    "        r.history['val_loss'][-1],\n",
    "        r.history['accuracy'][-1],\n",
    "        r.history['val_accuracy'][-1],\n",
    "        time_elapsed,\n",
    "        mauc,\n",
    "        madv\n",
    "    ]))\n",
    "    results_summary.append(summ)\n",
    "    print('='*40)\n",
    "\n",
    "print('Epochs, Dropout, Regularizer, Loss, Val loss, Accuracy, Val accuracy, Time, AUC, Advantage')\n",
    "for r in results_summary:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9afcf78b",
   "metadata": {},
   "source": [
    "# Differential privacy experiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7b8961c7",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DP-SGD with sampling rate = 0.2% and noise_multiplier = 12.73545208582121 iterated over 23500 steps satisfies differential privacy with eps = 0.1 and delta = 1e-06.\n",
      "Epoch 1/1000\n",
      "500/500 [==============================] - 12s 21ms/step - loss: 2.3054 - accuracy: 0.0984 - val_loss: 2.3055 - val_accuracy: 0.0947\n",
      "Epoch 2/1000\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 2.3050 - accuracy: 0.0932 - val_loss: 2.3048 - val_accuracy: 0.0899\n",
      "Epoch 3/1000\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 2.3040 - accuracy: 0.0904 - val_loss: 2.3033 - val_accuracy: 0.0927\n",
      "Epoch 4/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.3028 - accuracy: 0.0925 - val_loss: 2.3026 - val_accuracy: 0.0935\n",
      "Epoch 5/1000\n",
      "500/500 [==============================] - 11s 21ms/step - loss: 2.3022 - accuracy: 0.0966 - val_loss: 2.3019 - val_accuracy: 0.0984\n",
      "Epoch 6/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.3009 - accuracy: 0.1009 - val_loss: 2.3006 - val_accuracy: 0.1011\n",
      "Epoch 7/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.3001 - accuracy: 0.1001 - val_loss: 2.2996 - val_accuracy: 0.1017\n",
      "Epoch 8/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2990 - accuracy: 0.1018 - val_loss: 2.2991 - val_accuracy: 0.0982\n",
      "Epoch 9/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2987 - accuracy: 0.0989 - val_loss: 2.2984 - val_accuracy: 0.0989\n",
      "Epoch 10/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2977 - accuracy: 0.1010 - val_loss: 2.2977 - val_accuracy: 0.1038\n",
      "Epoch 11/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2969 - accuracy: 0.1068 - val_loss: 2.2972 - val_accuracy: 0.1024\n",
      "Epoch 12/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2966 - accuracy: 0.1000 - val_loss: 2.2965 - val_accuracy: 0.1031\n",
      "Epoch 13/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2961 - accuracy: 0.1037 - val_loss: 2.2962 - val_accuracy: 0.1016\n",
      "Epoch 14/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2958 - accuracy: 0.1097 - val_loss: 2.2958 - val_accuracy: 0.1089\n",
      "Epoch 15/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2951 - accuracy: 0.1116 - val_loss: 2.2957 - val_accuracy: 0.1105\n",
      "Epoch 16/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2948 - accuracy: 0.1132 - val_loss: 2.2952 - val_accuracy: 0.1143\n",
      "Epoch 17/1000\n",
      "500/500 [==============================] - 10s 21ms/step - loss: 2.2949 - accuracy: 0.1146 - val_loss: 2.2956 - val_accuracy: 0.1073\n",
      "Epoch 18/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2941 - accuracy: 0.1113 - val_loss: 2.2944 - val_accuracy: 0.1079\n",
      "Epoch 19/1000\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 2.2932 - accuracy: 0.1055 - val_loss: 2.2934 - val_accuracy: 0.1070\n",
      "Epoch 20/1000\n",
      "500/500 [==============================] - 10s 19ms/step - loss: 2.2927 - accuracy: 0.1064 - val_loss: 2.2929 - val_accuracy: 0.1091\n",
      "Epoch 21/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2921 - accuracy: 0.1068 - val_loss: 2.2921 - val_accuracy: 0.1136\n",
      "Epoch 22/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2914 - accuracy: 0.1092 - val_loss: 2.2920 - val_accuracy: 0.1068\n",
      "Epoch 23/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2910 - accuracy: 0.1054 - val_loss: 2.2910 - val_accuracy: 0.1030\n",
      "Epoch 24/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2904 - accuracy: 0.1092 - val_loss: 2.2908 - val_accuracy: 0.1090\n",
      "Epoch 25/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2904 - accuracy: 0.1117 - val_loss: 2.2903 - val_accuracy: 0.1088\n",
      "Epoch 26/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2905 - accuracy: 0.1117 - val_loss: 2.2911 - val_accuracy: 0.1125\n",
      "Epoch 27/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2901 - accuracy: 0.1165 - val_loss: 2.2897 - val_accuracy: 0.1172\n",
      "Epoch 28/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2887 - accuracy: 0.1150 - val_loss: 2.2882 - val_accuracy: 0.1152\n",
      "Epoch 29/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2876 - accuracy: 0.1142 - val_loss: 2.2878 - val_accuracy: 0.1129\n",
      "Epoch 30/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2865 - accuracy: 0.1172 - val_loss: 2.2863 - val_accuracy: 0.1200\n",
      "Epoch 31/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2859 - accuracy: 0.1169 - val_loss: 2.2870 - val_accuracy: 0.1137\n",
      "Epoch 32/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2871 - accuracy: 0.1113 - val_loss: 2.2877 - val_accuracy: 0.1138\n",
      "Epoch 33/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2878 - accuracy: 0.1133 - val_loss: 2.2880 - val_accuracy: 0.1126\n",
      "Epoch 34/1000\n",
      "500/500 [==============================] - 10s 20ms/step - loss: 2.2865 - accuracy: 0.1101 - val_loss: 2.2869 - val_accuracy: 0.1085\n",
      "Predict on train...\n",
      "Predict on test...\n",
      "Apply softmax to get probabilities from logits...\n",
      "Compute losses...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Usuario\\anaconda3\\envs\\tf-gpu\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best-performing attacks over all slices\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an AUC of 0.54 on slice CLASS=7\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.13 on slice CLASS=1\n",
      "\n",
      "Best-performing attacks over slice: \"Entire dataset\"\n",
      "  THRESHOLD_ATTACK (with 50000 training and 10000 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 10000 training and 10000 test examples) achieved an advantage of 0.03\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=0\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.51\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.06\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=1\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.13\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=2\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.04\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=3\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.52\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.07\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=4\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.06\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=5\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.07\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=6\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.51\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.05\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=7\"\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an AUC of 0.54\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.10\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=8\"\n",
      "  THRESHOLD_ATTACK (with 5000 training and 1000 test examples) achieved an AUC of 0.49\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.07\n",
      "\n",
      "Best-performing attacks over slice: \"CLASS=9\"\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an AUC of 0.52\n",
      "  LOGISTIC_REGRESSION (with 1000 training and 1000 test examples) achieved an advantage of 0.08\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=True\"\n",
      "  THRESHOLD_ATTACK (with 5434 training and 1085 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 1085 training and 1085 test examples) achieved an advantage of 0.07\n",
      "\n",
      "Best-performing attacks over slice: \"CORRECTLY_CLASSIFIED=False\"\n",
      "  THRESHOLD_ATTACK (with 44566 training and 8915 test examples) achieved an AUC of 0.50\n",
      "  LOGISTIC_REGRESSION (with 8915 training and 8915 test examples) achieved an advantage of 0.03\n",
      "========================================\n",
      "Epochs, Target epsilon, delta, C, Sigma, Sampling rate, Epsilon, Loss, Val loss, Accuracy, Val accuracy, Time, AUC, Advantage\n",
      "34, 0.1, 1e-06, 2.5, 12.73545208582121, 0.002, 0.10403653650998441, 2.286499261856079, 2.2869246006011963, 0.11011999845504761, 0.10849999636411667, 343.688759803772, 0.541728, 0.128\n"
     ]
    }
   ],
   "source": [
    "# TEST FOR DIFFERENT EPS\n",
    "results_summary = []\n",
    "\n",
    "n = X_train.shape[0]\n",
    "epochs = 50\n",
    "batch_size = 100\n",
    "microbatches = 10\n",
    "epsilons = [0.1,0.5,1,2,4,8,16,100,1000]\n",
    "delta = 1e-6\n",
    "min_noise = 1e-100\n",
    "l2_norm_clip = 2.5\n",
    "sampling_rate = batch_size / n\n",
    "attacks = 1\n",
    "\n",
    "for e in epsilons:\n",
    "    # Compute noise multiplier from target epsilon\n",
    "    noise_multiplier = compute_noise(n, batch_size, e, 47, delta, min_noise)\n",
    "    \n",
    "    # Instantiate network\n",
    "    model = create_dp_cnn(noise_multiplier, l2_norm_clip, microbatches)\n",
    "\n",
    "    # Train network\n",
    "    start_time = time.time()\n",
    "    r = model.fit(X_train, \n",
    "                 y_train, \n",
    "                 validation_data=(X_test, y_test), \n",
    "                 epochs=epochs, \n",
    "                 batch_size=batch_size,\n",
    "                 callbacks=[callback]\n",
    "                )\n",
    "    end_time = time.time()\n",
    "    time_elapsed = (end_time - start_time)\n",
    "    \n",
    "    # Compute epsilon\n",
    "    orders = [1 + x / 10. for x in range(1, 100)] + list(range(11, 101))\n",
    "    sampling_probability = batch_size / n\n",
    "    rdp = compute_rdp(q=sampling_probability,\n",
    "                    noise_multiplier=noise_multiplier,\n",
    "                    steps=len(r.history['loss']) * n // batch_size,\n",
    "                    orders=orders)\n",
    "    eps = get_privacy_spent(orders, rdp, target_delta=delta)\n",
    "    \n",
    "\n",
    "    # MIA \n",
    "    aauc = []\n",
    "    aadv = []\n",
    "    for _ in range(attacks):\n",
    "        auc, adv = membership_inference_attack(model, X_train, X_test, y_train, y_test)\n",
    "        aauc.append(auc)\n",
    "        aadv.append(adv)\n",
    "    mauc = sum(aauc) / attacks\n",
    "    madv = sum(aadv) / attacks\n",
    "\n",
    "    # Write result summary\n",
    "    summ = ', '.join(map(str,[\n",
    "          len(r.history['loss']),\n",
    "          e,\n",
    "          delta,\n",
    "          l2_norm_clip,\n",
    "          noise_multiplier,\n",
    "          sampling_rate,\n",
    "          eps[0],\n",
    "          r.history['loss'][-1], \n",
    "          r.history['val_loss'][-1],\n",
    "          r.history['accuracy'][-1],\n",
    "          r.history['val_accuracy'][-1],\n",
    "          time_elapsed,\n",
    "          mauc,\n",
    "          madv\n",
    "    ]))\n",
    "    results_summary.append(summ)\n",
    "    print('='*40)\n",
    "\n",
    "print('Epochs, Target epsilon, delta, C, Sigma, Sampling rate, Epsilon, Loss, Val loss, Accuracy, Val accuracy, Time, AUC, Advantage')\n",
    "for r in results_summary:\n",
    "    print(r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71fbeb59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
